{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "752e026a",
   "metadata": {},
   "source": [
    "# Social Media Post Generator - Tavilly Client + Claude "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d588e537",
   "metadata": {},
   "source": [
    "### Import Libraries and Api keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4167ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tavily import TavilyClient\n",
    "from anthropic import Anthropic\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "if ANTHROPIC_API_KEY is None:\n",
    "  raise Exception('Missing anthropic api key')\n",
    "\n",
    "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')\n",
    "if TAVILY_API_KEY is None:\n",
    "  raise Exception('Missing Tavily Client api key')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if OPENAI_API_KEY is None:\n",
    "  raise Exception(\"Missing open ai api key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3d5e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_raw_article(text: str) -> str:\n",
    "    # Remove typical image-related patterns\n",
    "    text = re.sub(r'\\[Image.*?\\]', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'(Figure|Image|Photo)[\\s\\S]{0,30}', '', text)\n",
    "    text = re.sub(r'https?://\\S+\\.(jpg|jpeg|png|gif)', '', text)  # Remove image URLs\n",
    "    # Strip excessive whitespace\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446a3ae",
   "metadata": {},
   "source": [
    "### Tavily - Fetch AI news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b97b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily = TavilyClient(api_key = TAVILY_API_KEY)\n",
    "today = datetime.now().strftime(\"%B %d, %Y\")  # e.g., \"July 16, 2025\"\n",
    "tavily_results = tavily.search(\n",
    "  query = f\"latest AI news as of {today} including breakthroughs\",\n",
    "  max_results = 5,\n",
    "  include_answer=True,\n",
    "  include_raw_content=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38efde85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'latest AI news as of July 16, 2025 including breakthroughs, enterprise use cases, research papers, and developments in large language models', 'follow_up_questions': None, 'answer': 'Recent AI breakthroughs include advanced large language models and significant enterprise applications. Key research papers have been published, and geopolitical impacts are being closely monitored. July 2025 saw notable developments in AI research and model architecture.', 'images': [], 'results': [{'url': 'https://nathanbenaich.substack.com/p/your-guide-to-ai-july-2025', 'title': 'July 2025 - by Nathan Benaich - Your guide to AI', 'content': 'What you need to know in AI across geopolitics, big tech, hardware, research, models, datasets, financings and exits over the last 4 weeks.', 'score': 0.7443038, 'raw_content': '![Guide to AI](https://substackcdn.com/image/fetch/$s_!_XP1!,w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6dc44416-e995-417b-bf9d-06b4e0c19f99_333x333.png)\\n\\n# [Guide to AI](/)\\n\\n#### Share this post\\n\\n![](https://substackcdn.com/image/fetch/$s_!WH2K!,w_520,h_272,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb17be655-a559-434f-bdac-63acfb66e8b3_1520x852.png)\\n![Guide to AI](https://substackcdn.com/image/fetch/$s_!_XP1!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6dc44416-e995-417b-bf9d-06b4e0c19f99_333x333.png)\\n\\n# Your guide to AI: July 2025\\n\\n![Nathan Benaich\\'s avatar](https://substackcdn.com/image/fetch/$s_!pLgq!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F93650730-02fe-4e6a-ba9b-0ede30a2fe0a_500x333.jpeg)\\n\\n#### Share this post\\n\\n![](https://substackcdn.com/image/fetch/$s_!WH2K!,w_520,h_272,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb17be655-a559-434f-bdac-63acfb66e8b3_1520x852.png)\\n![Guide to AI](https://substackcdn.com/image/fetch/$s_!_XP1!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6dc44416-e995-417b-bf9d-06b4e0c19f99_333x333.png)\\n\\nHi everyone!\\n\\nWelcome to the latest issue of your guide to AI, an editorialized newsletter covering the key developments in AI policy, research, industry, and start-ups over the last month. First up, a few reminders:\\n\\n**Research and Applied AI Summit 2025:** we’re sharing the [talk videos](https://www.youtube.com/channel/UCL78WE5txuSu94gY5qrvU8w) on our YouTube and [our writeups](https://press.airstreet.com/s/community) on Air Street Press.\\n\\n**State of AI Report:** we’ve begun crafting this year’s edition and invite you to submit research or industry data points/case studies that would provide for thought provoking analysis. Feel free to reply to this email if so!\\n\\nWe’ve published an update of the **[Compute Index](https://press.airstreet.com/p/state-of-ai-compute-index-v4-june-2025)** featuring new GPU cluster numbers and insights into which AI accelerators are used in various AI research areas.\\n\\n**Participate in the [State of AI Survey](https://airstreet.typeform.com/survey)**, it’ll take 10 mins and focuses on usage of GenAI. The results will be included in the State of AI Report this October.\\n\\n**Air Street Press** featured a number of pieces this past month including [our view](https://press.airstreet.com/p/uk-strategic-defence-review-2025-from-diagnosis) of the UK’s Strategic Defence Review and two op-eds published in Fortune, the first on the [sovereign AI paradox](https://press.airstreet.com/p/sovereign-ai-paradox) and the second on the [AI rollup](https://press.airstreet.com/p/ai-rollup-mirage) investment thesis mirage.\\n\\nI love hearing what you’re up to, so just hit reply or forward to your friends :-)\\n\\n### Meta’s AI superintelligence offensive\\n\\nIn response to internal challenges and a lukewarm reception of Llama 4, Meta has launched a significant restructuring of its AI initiatives. The company announced the formation of [Meta Superintelligence Labs](https://www.nytimes.com/2025/06/10/technology/meta-new-ai-lab-superintelligence.html), led by former Scale AI CEO Alexandr Wang as Chief AI Officer, ex-GitHub CEO Nat Friedman overseeing applied research, and investor Daniel Gross also joining the leadership team. This move follows [Meta\\'s $14.3 billion investment](https://www.bloomberg.com/news/articles/2025-06-13/meta-announces-scale-ai-investment-recruits-ceo-to-ai-unit) for a 49% stake in Scale AI. The deal effectively functions as a pseudo-acquisition despite its price tag and claims of operational independence, especially with [Google now preparing to exit](https://www.reuters.com/business/google-scale-ais-largest-customer-plans-split-after-meta-deal-sources-say-2025-06-13) from Scale as a major customer.\\n\\nIn addition, many headlines have been made of 8-9 figure offers being made to key talent, in particular from OpenAI. What Altman first made out to be a non-issue (“our best ppl aren’t leaving”) has transformed into an “oh shit, Meta did manage to lure (with a lotta cash) [key contributors](https://x.com/nathanbenaich/status/1939767860768706778) to major OpenAI products and research”. Taken together with its leadership reshuffle, Meta appears to be pivoting away from open weights and toward superintelligence, even though it\\'s unclear what that’ll mean.\\n\\nOn the note of talent movements, here is some [new data](https://www.signalfire.com/blog/signalfire-state-of-talent-report-2025) from SignalFire that tracks these recent trends:\\n\\n![](https://substackcdn.com/image/fetch/$s_!S3Zh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94f4c617-cf9a-4401-9af1-37e06fd9f4b8_1200x900.png)\\n![](https://substackcdn.com/image/fetch/$s_!T0bj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf6a60d6-45f6-4994-8218-34fb331e96fb_1200x900.png)\\n\\n### AI revenues are ramping\\n\\n[OpenAI](https://www.ft.com/content/1ffc5fe7-6872-42a0-8b98-dc685f9c33c6) reported an annual revenue run rate of $10 billion, while [Anthropic](https://www.theinformation.com/articles/anthropic-revenue-hits-4-billion-annual-pace-competition-cursor-intensifies?rc=yvsjfo) reached $4 billion. [Replit](https://www.linkedin.com/posts/steviecase_the-team-at-replit-just-hit-a-major-milestone-activity-7345550435035881472-l6UN/) announced it had grown from $10M to $100M too. These are amazing figures given that just a few years ago, we’d scoff at such an eventuality being realistic.\\n\\nMeanwhile, Apple isn’t making a whole lot of anything in AI. So much so that [news broke](https://archive.is/svBdY) that future versions of Siri will be powered by either OpenAI\\'s ChatGPT or Anthropic\\'s Claude, depending on user region and configuration. This is a big win for the model companies , particularly as Apple’s OS and hardware should (by all textbook accounts of technology strategy) have placed it in a prime position to implement a powerful AI assistant of its own.\\n\\n[Barclays](https://ukstories.microsoft.com/features/barclays-rolls-out-microsoft-365-copilot-to-100000-colleagues/) has rolled out Microsoft 365 Copilot to 100,000 employees, marking one of the largest deployments of AI productivity tools in a corporate environment. But concerns about AI model security have surfaced. Microsoft’s Copilot recently faced backlash following the \\'[EchoLeak](https://fortune.com/2025/06/11/microsoft-copilot-vulnerability-ai-agents-echoleak-hacking/) incident, where prompt injection and context bleed vulnerabilities allowed users to extract data from unrelated chat sessions, highlighting how agent memory and retrieval can be manipulated.\\n\\nMeanwhile, [Anthropic disclosed](https://www.anthropic.com/research/agentic-misalignment) that certain Claude models demonstrated unsafe behavior in long-horizon tasks, including strategies to avoid shutdown or obfuscate their reasoning under adversarial prompting. These incidents aren’t edge cases. As Copilot and Claude scale into real-world workflows, their brittleness under stress shows how little resilience current alignment techniques afford. The broader takeaway is that as enterprise deployments scale, surface area for failure expands dramatically, and real-world interactions expose failure modes far beyond benchmark coverage.\\n\\n### Regulatory and legal pressures\\n\\nIn a significant legal development, a U.S. federal court ordered Anthropic to disclose whether copyrighted books were used in training its Claude models. The ruling stems from ongoing litigation involving authors and publishers who allege that major AI companies have illegally scraped and reproduced their works under the guise of fair use. The plaintiffs cite evidence that outputs from Claude contain lengthy, verbatim excerpts from copyrighted texts, suggesting direct ingestion of protected material.\\n\\nU.S. District Judge William Alsup [ruled](https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.231.0_2.pdf) that Anthropic’s practice of destructively scanning legally purchased print books to train Claude constituted \"quintessentially transformative\" fair use under U.S. copyright law. This set a major precedent, affirming that AI developers may lawfully use copyrighted materials for training purposes when those materials are lawfully acquired. However, the court drew a firm line on the use of pirated content: evidence showed Anthropic had stored over 7 million books sourced from sites like Library Genesis and Pirate Library Mirror. Alsup ruled that retaining or training on pirated material falls outside fair use protections, even if later replaced with purchased copies.\\n\\nConsequently, Anthropic will face a jury trial in December 2025 to determine potential damages, which could reach up to $150,000 per infringed work. This mixed ruling offers a partial legal framework for training data provenance but raises the stakes around data sourcing practices across the AI sector. If upheld, the case could compel AI companies to publish detailed disclosures about the provenance of their training datasets or face increased legal exposure.\\n\\nThis case, alongside Reddit’s [lawsuit](https://www.wsj.com/tech/ai/reddit-lawsuit-anthropic-ai-3b9624dd) against Anthropic for unauthorized scraping, signals a continued battleground around data rights, where the contours of AI regulation are being drawn not just by lawmakers, but in the courts.\\n\\nSpeaking of regulation, there were [new congressional hearings](https://x.com/sjgadler/status/1937977548912398798) into the national security implications of dual-use foundation models, the adequacy of current voluntary safety commitments, and whether current legal frameworks can meaningfully constrain the most capable AI systems. Lawmakers scrutinized the limited enforcement power of agencies like NIST and the Department of Commerce, and debated proposals for a new federal oversight body specifically tasked with regulating advanced AI development.\\n\\nSeveral panelists, including leaders from top AI labs and academic policy researchers, advocated for mandatory reporting of safety evaluations and red-teaming results to regulators. Concerns were also raised about model accessibility, with some lawmakers supporting the idea of licensing for both model deployment and training runs over specific compute thresholds. While some proposals were ambitious—such as formal classification regimes or export-style controls for domestic models—others stressed the risk of overreach or bureaucratic stasis.\\n\\nCritics noted the fragmented nature of the current oversight ecosystem and warned that without binding legal mandates, industry self-governance is likely to fall short. The hearing spotlighted a core tension: calls for binding guardrails are growing, but existing agencies remain underpowered and jurisdictionally constrained. Proposals for licensing and classification regimes face both technical and political resistance. The absence of a coherent US regulatory framework stands in contrast to China’s escalating controls and the EU’s hardening enforcement mandates.\\n\\n### Autonomous vehicles\\n\\n[Wayve](https://x.com/alexgkendall/status/1932209972546560461?s=51&t=8YCMEcmVVXRPm8SXTMgdlw), in partnership with Uber, has initiated robotaxi services, and so has [Tesla](https://x.com/tesla/status/1936877624036307315?s=51&t=8YCMEcmVVXRPm8SXTMgdlw) with its robotaxis. Meanwhile, Wayve launched a [\"generalization world tour\"](https://x.com/wayve_ai/status/1932355193867296844?s=51&t=8YCMEcmVVXRPm8SXTMgdlw) to demonstrate its model\\'s capacity to operate in varied urban contexts worldwide. The tour aims to showcase generalization of their single driving model without geofencing or hand-coded interventions. While the company has not yet shared performance metrics or how its system handles corner cases, the videos are very impressive.\\n\\nAdding to the field’s momentum, [Waymo](https://waymo.com/research/scaling-perception-2025) published a new paper analyzing how scaling laws apply to autonomous driving. By training perception models across progressively larger fleets and datasets, the study demonstrated near power-law gains in performance with scale, mirroring patterns observed in language models. The results suggest that AV performance may be bottlenecked less by model architecture and more by data collection and integration scale. While the paper focused on perception rather than full-stack autonomy, it underscores a shift in AV research toward foundation-model-style scaling and away from narrow rule-based systems.\\n\\n![](https://substackcdn.com/image/fetch/$s_!xMnN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02c516fa-6e3c-496e-be94-2a48ec9e8f1c_1600x900.png)\\n\\n### More shades of safety\\n\\nAnthropic has published a series of studies aimed at stress-testing and evaluating the safety of advanced AI agents. The [Shade Arena](https://www.anthropic.com/research/shade-arena-sabotage-monitoring) framework evaluates sabotage and deceptive behavior in multi-agent games, showing that models fine-tuned for helpfulness still engage in covert competition when stakes are introduced. Their [multi-agent infrastructure](https://www.anthropic.com/engineering/built-multi-agent-research-system) supports long-horizon simulations that test delegation, coordination, and tool-use under uncertainty. These environments expose brittleness in model behavior that short, single-agent benchmarks miss.\\n\\nTheir paper on [agentic misalignment](https://www.anthropic.com/research/agentic-misalignment) categorizes failures along axes such as goal misgeneralization, covert optimization, and robustness to scrutiny. A key insight is that models may appear aligned under ordinary conditions but fail under adversarial or high-pressure setups, making post-deployment monitoring critical. What unites these studies is a shift in evaluation mindset: from static red teaming to dynamic environments where misalignment emerges under pressure or over time. The question is no longer “does it fail?” but “when, and how quietly?” Together, these findings push the frontier of AI evaluation from static benchmarks to dynamic, agentic behavior under pressure, and its real-world psychological spillovers.\\n\\nSeparately, [\"Hollowing out the brain with ChatGPT\"](https://arxiv.org/pdf/2506.08872) found that prolonged reliance on LLMs leads to decreased retention and originality in tasks like writing and problem-solving. Users became more fluent but less exploratory. This just goes to show that there aren’t any shortcuts to learning - you’ve got to just do the work and feel the pain.\\n\\n### China\\n\\nAccording to the Q2 2025 China AI report by [Artificial Analysis](https://artificialanalysis.ai/downloads/china-report/2025/Artificial-Analysis-State-of-AI-China-Q2-2025-Highlights.pdf), over 50 new national-level AI projects were launched this quarter. These span large model training clusters, edge AI deployment pilots, sovereign cloud infrastructure initiatives, and Beijing’s push to establish a national foundation model benchmark standard. Leading players include Baidu, Huawei, Tencent, iFlytek, and Inspur, each receiving targeted funding and policy incentives to build vertically integrated stacks.\\n\\nProvincial governments are also stepping up. For instance, Guangdong is investing in a compute subsidy program for startups, while Shanghai is piloting model evaluation frameworks under the Cyberspace Administration of China. The state is explicitly prioritizing alignment with ideological controls, including censorship tooling and model fine-tuning for adherence to \\'core socialist values.\\' This goes beyond Western-style safety to focus on normative steering of model outputs.\\n\\nChina’s AI ecosystem is also increasingly insular. Local cloud vendors have reduced reliance on US-origin chips, driven by supply chain disruptions and sanctions. Companies like Biren and Moore Threads are accelerating production of domestic accelerators. At the same time, reporting from [The Wall Street Journal](https://archive.is/8syqZ) and others has detailed how Chinese firms have been circumventing export restrictions by covertly importing restricted U.S. chips via intermediary countries. This chip smuggling ecosystem leverages gray-market suppliers in Southeast Asia and shell companies and underscores the continuing demand for top-tier GPUs, despite Beijing’s parallel push for domestic alternatives. Meanwhile, technical papers from Tsinghua and CAS show advances in bilingual pretraining, instruction tuning, and state-owned model architectures, often with limited international collaboration or transparency.\\n\\nIf the US is grappling with how to regulate foundation models, China is already piloting enforcement. A new [RAND analysis](https://www.rand.org/pubs/perspectives/PEA4012-1.html) highlights that Beijing\\'s framework emphasizes controllability, data sovereignty, and alignment with socialist values. The report details how China’s regulatory model is centrally planned but implemented regionally, with the Cyberspace Administration of China setting nationwide model registration rules and provincial authorities like those in Shanghai and Shenzhen enforcing them. It also notes the use of tiered licensing, where model providers must pass government audits and submit outputs for evaluation against political red lines. Developers are expected to pre-train on sanitized datasets and incorporate in-model filters for taboo content. RAND warns that while this framework enables strict enforcement, it may also hinder technical innovation and restrict access to diverse viewpoints needed for robust general-purpose AI.\\n\\n[Share](https://nathanbenaich.substack.com/p/your-guide-to-ai-july-2025?utm_source=substack&utm_medium=email&utm_content=share&action=share)\\n\\n### **Research papers**\\n\\n**[Boltz-2: Towards Accurate and Efficient Binding Affinity Prediction](https://jeremywohlwend.com/assets/boltz2.pdf)**, MIT CSAIL, Recursion, Valence Labs\\n\\nIn this paper, the authors present Boltz-2, a structural biology foundation model that advances both structure and binding affinity prediction for biomolecules. The model demonstrates improved structure prediction across various modalities and can better capture local protein dynamics through experimental method conditioning.\\n\\nMost significantly, Boltz-2 approaches the accuracy of free-energy perturbation methods for predicting binding affinities on benchmarks like FEP+ and CASP16, while being 1000× more computationally efficient. In virtual screening tests against the TYK2 target, Boltz-2 coupled with a generative model successfully identified novel, high-affinity binders.\\n\\nThe authors acknowledge limitations including variability in performance across different targets and dependence on accurate structure prediction for reliable affinity estimates. The model is released under a permissive license.\\n\\n**[AlphaGenome: advancing regulatory variant effect prediction with a unified DNA sequence model](https://www.biorxiv.org/content/10.1101/2025.06.25.661532v1.full.pdf)**, Google DeepMind.\\n\\nIn this paper, the authors introduce AlphaGenome, a deep learning model that predicts thousands of functional genomic tracks directly from 1 megabase of DNA sequence at single base-pair resolution. These tracks include gene expression, splicing, chromatin accessibility, histone modifications, transcription factor binding, and 3D chromatin contacts.\\n\\nAlphaGenome unifies multimodal prediction, long-range sequence context, and high resolution in a single framework. It is benchmarked against both specialized and generalist models, matching or exceeding the best available models on 24 out of 26 variant effect prediction tasks and 22 out of 24 genome track prediction tasks. Notably, it outperforms Borzoi and Enformer on eQTL effect prediction and surpasses specialized models like SpliceAI and ChromBPNet on splicing and chromatin accessibility tasks.\\n\\nThe model’s architecture leverages a U-Net-style encoder-decoder with transformers, and is trained using a two-stage process involving pretraining and distillation. The authors highlight that AlphaGenome’s unified approach enables efficient, simultaneous variant effect prediction across modalities, which is valuable for interpreting non-coding variants in disease, rare variant diagnostics, and large-scale genome analysis. Caveats include challenges in modeling very distal regulatory elements and tissue-specific effects, and the model’s current focus on human and mouse genomes.\\n\\n**[Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model](https://arxiv.org/pdf/2506.13642)**, Chinese Academy of Sciences.\\n\\nIn this paper, the authors introduce Stream-Omni, a model for more efficient multimodal interactions across text, vision, and speech. The key idea is to align modalities based on their relationship: using standard concatenation for vision-text alignment and a novel layer-dimension mapping for speech-text alignment.\\n\\nThis approach allows the model to achieve strong performance using only 23,000 hours of speech data, significantly less than many comparable models. It performs competitively on 11 visual understanding benchmarks (64.7 average) and knowledge-based spoken question answering (60.3 average accuracy for speech-to-text).\\n\\nThe model\\'s architecture allows it to simultaneously produce intermediate text transcriptions during speech interaction. This is relevant for creating more transparent and seamless real-world applications, such as interactive assistants, where users can see what the model is hearing in real-time.\\n\\n**[Revisiting Diffusion Models: From Generative Pre-training to One-Step Generation](https://arxiv.org/pdf/2506.09376)**, Tsinghua University, Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory.\\n\\nIn this paper, the authors propose a new perspective on diffusion models, viewing them as generative pre-training that can be efficiently converted to one-step generators. They identify a key limitation in traditional diffusion distillation: teacher and student models converge to different local minima, making direct imitation suboptimal. To solve this, they develop D2O (Diffusion to One-Step), which uses only a GAN objective without distillation losses.\\n\\nTheir most striking finding is that D2O-F (with 85% of parameters frozen during fine-tuning) achieves state-of-the-art results with minimal training data - requiring only 5M images to reach FID=1.16 on ImageNet 64x64 and FID=0.85 on FFHQ, while competing methods need hundreds of millions of images.\\n\\nThis could lead to significantly reduced computational resources for high-quality image generation, making these capabilities more accessible while revealing that diffusion models inherently contain one-step generation abilities that just need to be unlocked.\\n\\n**[Text-to-LoRA: Instant Transformer Adaption](https://arxiv.org/pdf/2506.06105)**, Sakana AI.\\n\\nIn this paper, the authors introduce Text-to-LoRA (T2L), a model that generates task-specific adapters for LLMs using only a natural language description. Instead of traditional fine-tuning, T2L is a hypernetwork that produces a Low-Rank Adaptation (LoRA) in a single, inexpensive forward pass.\\n\\nWhen trained on 479 tasks, T2L was tested on 10 unseen benchmarks. It generated useful LoRAs that outperformed a multi-task baseline (e.g., 67.7% vs. 66.3% average accuracy) and was over four times more computationally efficient than 3-shot in-context learning.\\n\\nA key caveat is that performance is sensitive to the quality of the text description. This research matters because it lowers the barrier for specializing foundation models, enabling users to adapt an AI for a new purpose simply by describing the task, which is useful for rapid, on-the-fly customization.\\n\\n**[How much do language models memorize?](https://www.arxiv.org/pdf/2505.24832)**, Meta FAIR, Google DeepMind, Cornell University\\n\\nIn this paper, the authors propose a new method for estimating language model memorization by separating it into unintended memorization (information about specific datasets) and generalization (information about the data-generation process).\\n\\nThe researchers trained hundreds of transformers (500K to 1.5B parameters) on synthetic and real data, discovering that GPT-family models have a capacity of approximately 3.6 bits-per-parameter.\\n\\nTheir experiments reveal that models memorize until their capacity fills, after which \"grokking\" begins - unintended memorization decreases as models start to generalize. The double descent phenomenon occurs precisely when dataset size exceeds model capacity.\\n\\nThe authors developed scaling laws showing that membership inference difficulty increases with dataset size and decreases with model capacity, predicting that most modern language models train on too much data for reliable membership inference.\\n\\n**[Training a scientific reasoning model for chemistry](https://arxiv.org/pdf/2506.17238)**, FutureHouse\\n\\nIn this paper, the authors present ether0, a 24-billion-parameter reasoning model designed for chemical tasks, demonstrating that RL can enable LLMs to perform complex scientific reasoning. The model was trained on 640,730 chemistry problems across 375 tasks, including molecular design, synthesis, and property prediction, using a combination of supervised fine-tuning and RL with verifiable rewards.\\n\\nThe experiments show ether0 outperforming general-purpose models, domain-specific models, and even human experts on open-ended tasks like retrosynthesis and SMILES generation. Notably, the model achieves higher accuracy with less data compared to traditional models, highlighting its efficiency. The authors also analyze the emergence of reasoning behaviors, such as backtracking and verification, which improve task performance.\\n\\nWhile the model excels in organic chemistry, it struggles with tasks outside its training distribution, such as inorganic chemistry.\\n\\n**[Self-Adapting Language Models](https://arxiv.org/pdf/2506.10943)**, MIT\\n\\nIn this paper, the authors introduce SEAL, a framework that enables LLMs to self-adapt by generating their own finetuning data and update directives. The approach uses RL to train models to produce “self-edits”, which are instructions for how to restructure or augment training data and select optimization parameters, such that subsequent weight updates improve downstream performance.\\n\\nThe authors evaluate SEAL in two domains: knowledge incorporation and few-shot learning. In knowledge incorporation, SEAL improves no-context SQuAD accuracy from 33.5% (finetuning on passage only) to 47.0%, outperforming synthetic data generated by GPT-4.1. In few-shot learning on ARC tasks, SEAL achieves a 72.5% adaptation success rate, compared to 20% for non-RL self-edits and 0% for in-context learning.\\n\\nThe paper, however, notes that SEAL is still susceptible to catastrophic forgetting and incurs higher computational costs due to its inner-loop finetuning.\\n\\n**[V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning](https://arxiv.org/pdf/2506.09985)**, Meta FAIR, Mila, Polytechnique Montréal\\n\\nIn this paper, the authors present V-JEPA 2, a self-supervised video model designed to understand, predict, and plan in the physical world. The model is pre-trained on over 1 million hours of internet-scale video and 1 million images, using a mask-denoising objective to predict representations of masked video segments. V-JEPA 2 achieves strong performance on motion understanding tasks, such as 77.3% top-1 accuracy on Something-Something v2, and state-of-the-art results in human action anticipation with 39.7 recall-at-5 on Epic-Kitchens-100.\\n\\nThe authors also align V-JEPA 2 with a large language model, achieving state-of-the-art results on video question-answering benchmarks like PerceptionTest (84.0%) and TempCompass (76.9%). Additionally, they extend the model to V-JEPA 2-AC, an action-conditioned world model trained on 62 hours of robot interaction data, enabling zero-shot robotic manipulation tasks like pick-and-place.\\n\\n**[Development and validation of an autonomous artificial intelligence agent for clinical decision-making in oncology](https://www.nature.com/articles/s43018-025-00991-6)**, Heidelberg University Hospital and Technical University Dresden\\n\\nIn this paper, the authors develop and evaluate an autonomous AI agent for clinical decision-making in oncology, integrating GPT-4 with multimodal precision oncology tools. The system combines language modeling with vision transformers for detecting microsatellite instability and KRAS/BRAF mutations from histopathology, MedSAM for radiological image segmentation, and web-based search tools like OncoKB, PubMed, and Google.\\n\\nBenchmarked on 20 realistic multimodal patient cases, the agent autonomously selected and used appropriate tools with 87.5% accuracy, reached correct clinical conclusions in 91% of cases, and accurately cited relevant guidelines 75.5% of the time. Compared to GPT-4 alone, which achieved only 30.3% completeness, the integrated agent reached 87.2%.\\n\\n**[Sequential Diagnosis with Language Models](https://arxiv.org/pdf/2506.22405)**, Microsoft AI\\n\\nIn this paper, the authors introduce the Sequential Diagnosis Benchmark (SDBench), which transforms 304 challenging New England Journal of Medicine cases into interactive, stepwise diagnostic tasks. Unlike static vignettes, SDBench requires agents (human or AI) to iteratively ask questions, order tests, and make cost-sensitive decisions, closely mirroring real clinical workflows.\\n\\nThe authors present the MAI Diagnostic Orchestrator (MAI-DxO), a model-agnostic system that simulates a panel of virtual physicians, each with specialized roles, to collaboratively refine diagnoses and select high-value tests. When paired with OpenAI’s o3 model, MAI-DxO achieves 80% diagnostic accuracy—four times higher than the 20% average of experienced physicians—while reducing diagnostic costs by 20% compared to physicians and 70% compared to off-the-shelf o3.\\n\\nThe research highlights that structured, multi-agent orchestration can improve both accuracy and cost-efficiency in AI-driven diagnosis, suggesting practical applications for clinical decision support and resource-limited healthcare settings.\\n\\n**[Reinforcement Learning Teachers of Test Time Scaling](https://arxiv.org/pdf/2506.08388)**, Sakana AI\\n\\nIn this paper, the authors introduce Reinforcement-Learned Teachers (RLTs), a new framework for training language models to generate high-quality reasoning traces for downstream distillation, rather than solving problems from scratch. Unlike traditional RL approaches that rely on sparse, correctness-based rewards, RLTs are trained with dense rewards by providing both the question and its solution, and optimizing the model to produce explanations that help a student model learn.\\n\\nExperiments show that a 7B parameter RLT can outperform existing distillation pipelines that use much larger models, both in training smaller students and in cold-starting RL for future iterations. Benchmarks on math and science tasks (AIME, MATH, GPQA) demonstrate higher or comparable accuracy with less computational cost. The study also finds that RLTs transfer well to new domains without retraining.\\n\\nThis research matters because it offers a more efficient and reusable way to generate reasoning data for training and improving language models, potentially lowering the barrier for developing strong AI systems in real-world applications.\\n\\n**[ESSENTIAL-WEB V1.0: 24T tokens of organized web data](https://arxiv.org/pdf/2506.14111)**, Essential AI\\n\\nIn this paper, the authors introduce ESSENTIAL-WEB V1.0, a 24-trillion-token dataset annotated with a 12-category taxonomy covering topics, content complexity, and quality. The dataset enables rapid, SQL-like filtering to curate domain-specific corpora for math, code, STEM, and medical domains without bespoke pipelines.\\n\\nExperiments show that taxonomy-curated datasets perform competitively with or surpass state-of-the-art (SOTA) alternatives. For instance, the taxonomy-based math dataset achieves results within 8% of SOTA on GSM8K, while STEM and web code datasets outperform SOTA by 24.5% and 14.3%, respectively. The medical dataset improves accuracy by 8.6% over existing baselines.\\n\\nThe authors also develop EAI-Distill-0.5b, a 0.5B-parameter classifier that labels documents 50x faster than its teacher model, Qwen2.5-32B-Instruct, while maintaining high annotation quality.\\n\\nThis research matters because it democratizes access to high-quality, domain-specific datasets, reducing the cost and complexity of training AI models. Real-world applications include improving LLMs for education, healthcare, and technical domains.\\n\\n**[Thought Anchors: Which LLM Reasoning Steps Matter?](https://arxiv.org/pdf/2506.19143)** Duke University, Alphabet\\n\\nIn this paper, the authors investigate reasoning processes in large language models (LLMs) by analyzing sentence-level reasoning traces. They introduce three methods: black-box resampling, white-box attention aggregation, and causal attribution through attention suppression. These methods identify \"thought anchors,\" critical reasoning steps that disproportionately influence subsequent reasoning and final answers.\\n\\nThe study finds that sentences related to planning and uncertainty management have higher counterfactual importance than those focused on computation or fact retrieval. Receiver attention heads, which focus on specific sentences, are more prevalent in reasoning models and play a significant role in structuring reasoning traces. Ablating these heads reduces model accuracy more than random head ablation, highlighting their importance.\\n\\nThis research provides tools for debugging and improving reasoning models, with potential applications in enhancing model reliability and interpretability. It is particularly relevant for tasks requiring multi-step reasoning, such as mathematical problem-solving or complex decision-making in real-world scenarios.\\n\\n[Share](https://nathanbenaich.substack.com/p/your-guide-to-ai-july-2025?utm_source=substack&utm_medium=email&utm_content=share&action=share)\\n\\n### **Investments**\\n\\n[Toma](https://techcrunch.com/2025/06/05/tomas-ai-voice-agents-have-taken-off-at-car-dealerships-and-attracted-funding-from-a16z/), the AI voice-agent company for car dealerships, raised a $17 M Series A financing round from a16z and Y Combinator.\\n\\n[Anduril](https://techcrunch.com/2025/06/05/anduril-raises-2-5b-at-30-5b-valuation-led-by-founders-fund/), the US defense company, raised a $2.5B financing round at a $30.5 billion valuation. The company has been making noise recently about going public soon.\\n\\n[xAI](https://x.com/morganstanley/status/1939768047780172184), Elon’s AI company, raised $5B in a financing round from “prominent global debt investors” facilitated by Morgan Stanley and separately obtained a $5B strategic equity investment.\\n\\n[Crete Professionals Alliance](https://www.reuters.com/business/thrive-backed-accounting-firm-crete-spend-500-million-ai-roll-up-2025-06-04/), an AI-driven accounting platform, raised a few-hundred-million-dollar round from Thrive Capital, ZBS Partners and Bessemer Venture Partners.  \\n[Sintra](https://tech.eu/2025/06/10/lithuanian-ai-startup-sintra-secures-17m-seed-empowering-smbs-with-ai-helpers/), the Lithuanian AI startup empowering small businesses with AI helpers, raised a $17M seed round from Earlybird VC, Inovo and Practica Capital.\\n\\n[Shinkei Systems](https://www.foodbev.com/news/seafood-robotics-company-shinkei-systems-secures-22m-in-series-a-funding/), a seafood-robotics company integrating advanced robotics and AI with traditional fishing methods, raised $22M in a Series A co-led by Founders Fund and Interlagos.\\n\\n[Skyramp](https://www.skyramp.dev/blog-all/skyramp-launch), the AI-driven software-testing-automation company, raised a $10M seed round led by Sequoia Capital.\\n\\n[Crusoe](https://crusoe.ai/newsroom/crusoe-secures-usd750-million-credit-facility-from-brookfield-to-accelerate/), a cloud infrastructure startup focused on AI data centers, raised a $750M credit line from Brookfield Asset Management.\\n\\n[Yupp](https://siliconangle.com/2025/06/13/yupp-launches-33m-build-crypto-incentivized-ai-evaluation-platform/), a platform for crypto-incentivized AI-model evaluation, raised a $33M seed round led by a16z crypto with participation from Jeff Dean and Biz Stone.\\n\\n[Gecko Robotics](https://www.airforce-technology.com/news/gecko-double-valuation-to-1-25bn-reaching-unicorn-status/), the Pittsburgh company using AI and robotics to modernize maintenance techniques in defense, raised a $1.25B Series D led by Cox Enterprises with USIT and Founders Fund.\\n\\n[CX2](https://www.axios.com/2025/05/22/cx2-funding-mintz-electronic-warfare), a defense-technology company developing intelligent multi-domain electronic-warfare capabilities, raised a $31M Series A led by Point72 Ventures with Andreessen Horowitz and 8VC.\\n\\n[Helsing](https://www.ft.com/content/cdc02d96-13b5-4ca2-aa0b-1fc7568e9fa0), the German defense AI company, raised €600M in a round led by Spotify’s Daniel Ek.\\n\\n[Nabla](https://www.prnewswire.com/news-releases/nabla-raises-70m-series-c-to-deliver-agentic-ai-to-the-heart-of-clinical-workflows-bringing-total-funding-to-120m-302483646.html), the clinical AI assistant, raised a $70M Series C from HV Capital and Highland Europe.  \\n[Browserbase](https://www.upstartsmedia.com/p/browserbase-raises-40m-and-launches-director?hide_intro_popup=true), the infrastructure startup behind headless browsers, raised a $40M Series B at a $300M valuation from Notable Capital, Kleiner Perkins and CRV.\\n\\n[Ramp](https://www.prnewswire.com/news-releases/ramp-raises-200m-series-e-at-16b-valuation-as-companies-of-all-sizes-choose-ai-powered-finance-platform-302483377.html), the spend management platform, raised a $200M Series E at a $16B valuation from Founders Fund, Thrive Capital and General Catalyst.\\n\\n[Applied Intuition](https://www.appliedintuition.com/blog/series-f), a pioneer of AI simulation software for autonomy in transportation and defense, raised a Series F at a $15B valuation from BlackRock and Kleiner Perkins.\\n\\n[Profound](https://www.tryprofound.com/blog/series-a), the platform helping marketers optimize presence in AI responses, raised a $20M Series A from Kleiner Perkins, Khosla Ventures and NVIDIA NVentures.\\n\\n[Maven AGI](https://www.mavenagi.com/resources/post/series-b), a customer experience AI company, raised a $50M Series B from Dell Technologies Capital, Cisco Investments and SE Ventures.\\n\\n[Thinking Machines Lab](https://www.ft.com/content/9edc67e6-96a9-4d2b-820d-57bc1279e358), Mira Murati’s AGI company, raised $2B at a $10B valuation led by Andreessen Horowitz.\\n\\n[Commure](https://www.commure.com/blog/commure-secures-200m-to-accelerate-ai-powered-healthcare-transformation), the AI-powered healthcare company, raised $200M in growth capital from General Catalyst’s CVF.\\n\\n[Decagon](https://decagon.ai/resources/series-c-announcement), the conversational AI company, raised a $131M Series C at a $1.5B valuation from Accel and Andreessen Horowitz.\\n\\n[Genesis Robotics](https://sifted.eu/articles/exclusive-genesis-robotics-85m-round), a full-stack robotics company built around the generative physics engine by the [same name](https://genesis-embodied-ai.github.io/), raised an $85M round co-led by Khosla Ventures and Eclipse Ventures.\\n\\n[Abridge](https://techcrunch.com/2025/06/24/in-just-4-months-ai-medical-scribe-abridge-doubles-valuation-to-5-3b), the medical notes automation startup, raised a $300M Series E at a $5.3B valuation from Andreessen Horowitz and Khosla Ventures.\\n\\n[OpenRouter](https://www.globenewswire.com/news-release/2025/06/25/3105125/0/en/OpenRouter-raises-40-million-to-scale-up-multi-model-inference-for-enterprise.html), the unified interface for LLM inference, raised $40M across seed and Series A led by Andreessen Horowitz and Menlo Ventures.\\n\\n[Metaview](https://fortune.com/2025/06/25/uber-palantir-alums-metaview-raise-35m-ai-revolution-recruitment-hiring/), the AI recruitment tech company, raised a $35M Series B led by Google Ventures with Plural and Vertex Ventures.\\n\\n[Wispr Flow](https://techcrunch.com/2025/06/24/wispr-flow-raises-30m-from-menlo-ventures-for-its-ai-powered-dictation-app/), the AI-powered dictation app, raised a $30M Series A from Menlo Ventures and NEA.\\n\\n[Lyceum](https://tech.eu/2025/06/24/sovereign-by-design-lyceum-emerges-with-eur103m-to-redefine-cloud-infrastructure-in-europe/), a “sovereign” cloud provider for AI, raised a €10.3M pre-seed led by Redalpine with 10x Founders.\\n\\n[Nominal](https://blog.nominal.io/series-b), modernizing hardware testing, raised a $75M Series B led by Sequoia Capital.\\n\\n[Glean](https://www.glean.com/press/glean-raises-150m-series-f-at-7-2b-valuation-to-accelerate-enterprise-ai-agent-innovation-globally?utm_source=chatgpt.com), the enterprise search company, raised a $150M Series F at a $7.2B valuation led by Wellington Management.\\n\\n[Pano AI](https://www.globenewswire.com/news-release/2025/06/16/3099902/0/en/Wildfire-Tech-Comes-of-Age-Pano-AI-Raises-44M-Series-B-Led-by-Giant-Ventures-to-Scale-Early-Detection-Infrastructure.html?utm_source=chatgpt.com), the wildfire-detection company, raised a $44M Series B from Giant Ventures, Liberty Mutual Strategic Ventures and Tokio Marine Future Fund.\\n\\n[Traversal](https://fortune.com/2025/06/18/traversal-emerges-from-stealth-with-48-million-from-sequoia-and-kleiner-perkins-to-reimagine-site-reliability-in-the-ai-era/), a startup focused on observability and site reliability engineering, raised $48M in its seed and Series A financing rounds led by Sequoia and Kleiner Perkins.\\n\\n[Delphi](https://www.delphi.ai/blog/delphi-raises-16m-series-a-from-sequoia), the AI platform for creating interactive \"digital minds,\" raised a $16M Series A from Sequoia Capital, with participation from Menlo & Anthropic’s Anthology Fund and Proximity Ventures.\\n\\n### Rumored investments\\n\\n[Lovable](https://techcrunch.com/2025/07/02/lovable-on-track-to-raise-150m-at-2b-valuation/), the Swedish AI startup vibe coding frontend applications, is rumored to be raising $150M at a $2B valuation.\\n\\n[PhysicsX](https://www.ft.com/content/db2b25e0-da61-42d3-932a-991b12e5476a), the UK physics simulation startup working in the industrial and defense sectors, is nearing a $1B valuation in its latest round.\\n\\n### **Acquisitions**\\n\\n[Qualcomm](https://investor.qualcomm.com/news-events/press-releases/news-details/2025/Qualcomm-to-Acquire-Alphawave-Semi/default.aspx), the US chipmaker, acquired Alphawave, a UK-based public company building semiconductors, for $2.4B. The company makes high-speed connectivity and compute chiplets, enabling fast data transfer with lower power consumption for applications like data centers, AI, 5G, and autonomous vehicles. This connectivity IP is said to complement Qualcomm\\'s existing CPU and NPU processors, particularly for AI workloads.\\n\\n[Clio](https://www.clio.com/about/press/clio-signs-definitive-agreement-to-acquire-vlex/), the legal-tech leader, acquired vLex for $1B in cash and stock. This deal sees Clio bolt vLex’s AI-powered legal-research engine onto its practice-management suite so lawyers can search the world’s case law, draft filings, bill clients and track matters inside a single “legal OS.” The deal fast-forwards Clio’s agentic-AI roadmap, lets it sell up-market to large firms and new civil-law jurisdictions, and gives the combined company a proprietary corpus of workflow and primary-law data that can feed its own domain-specific LLMs while trimming licensing costs.\\n\\n[Figma](https://fortune.com/2025/07/02/figma-ipo-s-1-filing-growth-profitability-dual-class-share-structure-dylan-field-nyse-fig/), the design collaboration software company, filed for an IPO expected to raise up to $1.5B at a $15-20B valuation. This is a huge deal for the tech industry following the company’s failed $20B acquisition by Adobe due to anti-trust. Figma has since accelerated to almost $800m in revenue with 13M monthly active users and 95% of the Fortune 500 companies on its platform. The company has pushed into generative AI, launching new products such as Make, and weaving an AI assistant into its core surface.\\n\\n[Predibase](https://predibase.com/blog/predibase-will-be-joining-forces-with-rubrik), the AI company spun out of Chris Re’s group at Stanford to productise Ludvig, was acquired by Rubrik (a publicly listed cybersecurity company) to accelerate agentic-AI adoption. The price was undisclosed and rumored to be above $100M.\\n\\n[Helsing](https://www.ft.com/content/cdc02d96-13b5-4ca2-aa0b-1fc7568e9fa0), a German company specializing in AI and software solutions for defense, acquired Grob Aircraft, the producer of the G120TP military trainer, from H3 Aerospace. While the deal price was not disclosed, the rationale looks to be about vertical integration. By bringing a 275-person composite-aircraft factory and its G 120-series trainer line in-house, Helsing gains a purpose-built airframe on which it can iterate and certify its Cirra electronic-warfare AI and other onboard autonomy much faster than if it had to rely on third-party OEMs. The move deepens an existing test-bed partnership, anchors production in Europe and gives Helsing its own hardware-plus-software stack. This is an essential step toward fielding scalable, AI-native surveillance drones and light combat aircraft while reinforcing Europe’s drive for defence-technology sovereignty.\\n\\n[CoreWeave](https://coreweave.com/news/coreweave-to-acquire-core-scientific), the AI hyperscaler, acquired Core Scientific, a leading data center infrastructure provider, in an all-stock transaction valued at approximately $9 billion.\\n\\n[Superhuman](https://x.com/Superhuman/status/1940078856586571811), the email productivity company, was acquired by Grammarly. The acquisition price was not disclosed.\\n\\n[Seek AI](https://techcrunch.com/2025/06/02/ibm-acquires-data-analysis-startup-seek-ai-opens-ai-accelerator-in-nyc/), enabling natural language queries on enterprise data, was acquired by IBM for an undisclosed price.\\n\\n[Brainlab](https://www.reuters.com/business/finance/brainlab-ipo-expected-price-80-euros-per-share-bookrunner-says-2025-06-30/), the German med-tech firm that specializes in robotic surgery equipment and medical imaging tools, plans an IPO at €80 per share valuing the company at €1.7-2.1B.\\n\\n[Snyk](https://snyk.io/news/snyk-acquires-invariant-labs-to-accelerate-agentic-ai-security-innovation/), the secure-AI software leader, acquired Invariant Labs for an undisclosed price. The startup was spun out of an ETHZ lab that previously spawned DeepCode, also previously acquired by Snyk. Invariant was focused on productivising research to make agents more secure (e.g. [LMQL](https://github.com/eth-sri/lmql)).\\n\\nThe team behind [Crossing Minds](https://techcrunch.com/2025/06/27/openai-hires-team-behind-ai-recommendation-startup-crossing-minds/), an AI-recommendation startup, was acquired by OpenAI.\\n\\n#### Share this post\\n\\n![](https://substackcdn.com/image/fetch/$s_!WH2K!,w_520,h_272,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb17be655-a559-434f-bdac-63acfb66e8b3_1520x852.png)\\n![Guide to AI](https://substackcdn.com/image/fetch/$s_!_XP1!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6dc44416-e995-417b-bf9d-06b4e0c19f99_333x333.png)\\n\\n#### Discussion about this post\\n\\n![User\\'s avatar](https://substackcdn.com/image/fetch/$s_!TnFC!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png)\\n![Renaud Gaudron\\'s avatar](https://substackcdn.com/image/fetch/$s_!Ienv!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e554bad-b3bf-4e18-9339-2d02d879a40d_480x488.png)\\n\\nGreat summary! Thanks for sharing (and for including a voiceover!)\\n\\nNo posts\\n\\nReady for more?\\n\\n#### Share'}, {'url': 'https://www.crescendo.ai/news/latest-ai-news-and-updates', 'title': 'Latest AI Breakthroughs and News: May, June, July 2025', 'content': \"Wondering what's happening in the AI world? Here are the latest AI breakthroughs and news that are shaping the world around us!\", 'score': 0.6654328, 'raw_content': None}, {'url': 'https://www.techtarget.com/whatis/feature/12-of-the-best-large-language-models', 'title': '27 of the best large language models in 2025 - TechTarget', 'content': 'Below are some of the most relevant large language models today. They do natural language processing and influence the architecture of future models.', 'score': 0.585789, 'raw_content': '## Generative artificial intelligence, or GenAI, uses sophisticated algorithms to organize large, complex data sets into meaningful clusters of information to create new content, including text, images and audio, in response to a query or prompt. While the technology is still in relatively early -- and volatile -- days, progress thus far has already resulted in generative AI fundamentally changing enterprise technology and transforming how businesses operate. This guide takes a deeper look at how GenAI works and its implications, with hyperlinks throughout to guide you to articles, tips and definitions providing even more detailed explanations.\\n\\n# 27 of the best large language models in 2025\\n\\n## Large language models have been affecting search for years and have been brought to the forefront by ChatGPT and other chatbots.\\n\\nLarge language models are the dynamite behind the\\xa0[generative AI](https://www.techtarget.com/searchenterpriseai/definition/generative-AI)\\xa0boom. However, they\\'ve been around for a while.\\n\\n[LLMs](https://www.techtarget.com/whatis/definition/large-language-model-LLM)\\xa0are black box AI systems that use deep learning on extremely large datasets to understand and generate new text. Modern LLMs began taking shape in 2014 when the attention mechanism -- a machine learning technique designed to mimic human cognitive attention -- was introduced in a\\xa0[research paper](https://arxiv.org/abs/1409.0473)\\xa0titled \"Neural Machine Translation by Jointly Learning to Align and Translate.\" In 2017, that attention mechanism was honed with the introduction of the transformer model in another\\xa0[paper](https://arxiv.org/abs/1706.03762), \"Attention Is All You Need.\"\\n\\nSome of the most well-known language models today are based on the transformer model, including the\\xa0[generative pre-trained transformer series](https://www.techtarget.com/searchenterpriseai/feature/ChatGPT-vs-GPT-How-are-they-different)\\xa0of LLMs and bidirectional encoder representations from transformers (BERT).\\n\\n[ChatGPT](https://www.techtarget.com/whatis/definition/ChatGPT), which runs on a set of language models from OpenAI, attracted more than 100 million users just two months after its release in 2022. Since then, many competing models have been released. Some belong to big companies such as Google, Amazon and Microsoft; others are open source.\\n\\nConstant developments in the field can be difficult to keep track of. Here are some of the most influential models, both past and present. Included in it are models that paved the way for today\\'s leaders as well as those that could have a significant effect in the future.\\n\\nThis article is part of\\n\\n### [What is GenAI? Generative AI explained](https://www.techtarget.com/searchenterpriseai/definition/generative-AI)\\n\\n## Top current LLMs\\n\\nBelow are some of the most relevant large language models today. They do natural language processing and influence the architecture of future models.\\n\\n### BERT\\n\\n[BERT](https://www.techtarget.com/searchenterpriseai/definition/BERT-language-model)\\xa0is a family of LLMs that Google introduced in 2018. BERT is a\\xa0[transformer-based](https://www.techtarget.com/searchenterpriseai/tip/GAN-vs-transformer-models-Comparing-architectures-and-uses)\\xa0model that can convert sequences of data to other sequences of data. BERT\\'s architecture is a stack of transformer encoders and features 342 million parameters. BERT was pre-trained on a large corpus of data then fine-tuned to perform specific tasks along with natural language inference and sentence text similarity. It was used to improve query understanding in the 2019 iteration of Google search.\\n\\n### Claude\\n\\nThe\\xa0[Claude LLM](https://www.techtarget.com/searchenterpriseai/feature/Claude-AI-vs-ChatGPT-How-do-they-compare)\\xa0focuses on constitutional AI, which shapes AI outputs guided by a set of principles that aim to make the AI assistant it powers helpful, harmless and accurate. Claude was created by the company Anthropic. Claude\\'s latest iterations understand nuance, humor and complex instructions better than earlier versions of the LLM. They also have broad programming capabilities that make them well-suited for application development.\\n\\nThere are three primary branches of Claude -- Opus, Haiku and Sonnet. The Claude Sonnet 4 and Claude Opus 4 models debuted in early 2025. Opus 4, the premium model, can perform long-running tasks and [agentic](https://www.techtarget.com/searchenterpriseai/definition/agentic-AI) workflows. Sonnet 4, the efficiency-focused model, shows continued improvement in coding, reasoning and instruction-following compared to previous iterations. Both models also include:\\n\\nIn October 2024, Claude added an experimental\\xa0[computer-use AI tool](https://www.techtarget.com/searchenterpriseai/news/366613946/Anthropic-adds-computer-use-AI-tool-to-Claude) in public beta that enables the LLM to use a computer like a human does. It\\'s available to developers via the API.\\n\\n### Cohere\\n\\nCohere is an enterprise AI platform that provides several LLMs including Command, Rerank and Embed. These\\xa0[LLMs can be custom-trained](https://www.techtarget.com/searchenterpriseai/tip/How-to-train-an-LLM-on-your-own-data)\\xa0and fine-tuned to a specific company\\'s use case. The company that created the Cohere LLM was founded by one of the authors of Attention Is All You Need.\\n\\n### DeepSeek-R1\\n\\n[DeepSeek](https://www.techtarget.com/whatis/feature/DeepSeek-explained-Everything-you-need-to-know)-R1 is an open-source reasoning model for tasks with complex reasoning, mathematical problem-solving and logical inference. The model uses reinforcement learning techniques to refine its reasoning ability and solve complex problems. DeepSeek-R1 can perform critical problem-solving through self-verification, [chain-of-thought](https://www.techtarget.com/searchenterpriseai/definition/chain-of-thought-prompting) reasoning and reflection.\\n\\n### Ernie\\n\\nErnie is Baidu\\'s large language model powering the Ernie chatbot. The bot was released in August 2023 and has garnered more than 45 million users. Near the time of its release, it was rumored to have 10 trillion parameters, which turned out to be an overestimation -- later models have parameter counts in the billions. More recent versions of the Ernie chatbot include Ernie 4.5 and Ernie X1. The recent models are based on a [mixture-of-experts](https://www.techtarget.com/searchenterpriseai/feature/Mixture-of-experts-models-explained-What-you-need-to-know) architecture. Baidu open sourced it\\'s Ernie 4.5 LLM series in 2025.\\n\\n### Falcon\\n\\nFalcon is a family of transformer-based modelsdeveloped by the Technology Innovation Institute. It is open source and has multi-lingual capabilities. Falcon 2 is available in an 11 billion parameter version that provides [multimodal](https://www.techtarget.com/searchenterpriseai/definition/multimodal-AI) capabilities for both text and vision. Falcon 3 is available in several sizes ranging from 1-10 billion parameters.\\n\\nThe Falcon series also includes a pair of larger models with Falcon 40B and Falcon 180B, as well as several specialized models. Falcon models are available on GitHub as well as on cloud providers including Amazon.\\n\\n### Gemini\\n\\n[Gemini](https://www.techtarget.com/searchenterpriseai/definition/Google-Bard)\\xa0is Google\\'s family of LLMs that power the company\\'s chatbot of the same name. The model replaced Palm in powering the chatbot, which was rebranded from Bard to Gemini upon the model switch. Gemini models are multimodal, meaning they can handle images, audio and video as well as text. Gemini is also integrated in many Google applications and products. It comes in several sizes -- Ultra, Pro, Flash and Nano. Ultra is the largest and most capable model, Pro is the mid-tier model, Flash prioritizes speed for agentic systems and real-time applications, and Nano is the smallest model, designed for efficiency with on-device tasks.\\n\\nAmong the most recent models at the time of this writing is [Gemini 2.5 Pro](https://www.techtarget.com/whatis/feature/Google-Gemini-25-Pro-explained-Everything-you-need-to-know) and Gemini 2.5 Flash.\\n\\n### Gemma\\n\\n[Gemma](https://www.techtarget.com/searchenterpriseai/definition/Gemma)\\xa0is a family of open-source language models from Google that were trained on the same resources as Gemini. Gemma 2 was released in June 2024 in two sizes -- a 9 billion parameter model and a 27 billion parameter model. Gemma 3 was released in March 2025, with 1B, 4B, 12B and 27B versions, and has expanded capabilities. Gemma models can\\xa0[run locally](https://www.techtarget.com/searchenterpriseai/tip/How-to-run-LLMs-locally-Hardware-tools-and-best-practices)\\xa0on a personal computer, and are also available in Google Vertex AI.\\n\\n### GPT-3\\n\\n[GPT-3](https://www.techtarget.com/searchenterpriseai/definition/GPT-3)\\xa0is OpenAI\\'s large language model with more than 175 billion parameters, released in 2020. GPT-3 uses a decoder-only transformer architecture. GPT-3 is 10 times larger than its predecessor. GPT-3\\'s training data includes Common Crawl, WebText2, Books1, Books2 and Wikipedia.\\n\\nGPT-3 is the last of the GPT series of models in which OpenAI made the precise parameter counts publicly available. The GPT series was first introduced in 2018 with OpenAI\\'s paper \"Improving Language Understanding by Generative Pre-Training.\"\\n\\n### GPT-3.5\\n\\nGPT-3.5 is an upgraded version of GPT-3. It was fine-tuned using\\xa0[reinforcement learning from human feedback](https://www.techtarget.com/whatis/definition/reinforcement-learning-from-human-feedback-RLHF). There are several models, with GPT-3.5 Turbo being the most capable, according to OpenAI. GPT-3.5\\'s training data extends to September 2021.\\n\\nIt was also integrated into the Bing search engine but was replaced with GPT-4.\\n\\n### GPT-4\\n\\n[GPT-4](https://www.techtarget.com/whatis/definition/GPT-4) was released in 2023. Like the others in the OpenAI GPT family, it\\'s a\\xa0[transformer-based model](https://www.techtarget.com/searchenterpriseai/definition/transformer-model). Unlike the others, its parameter count has not been released to the public, though there are rumors that the model has more than 1 trillion. OpenAI describes GPT-4 as a multimodal model, meaning it can\\xa0[process and generate both language and images](https://www.techtarget.com/searchenterpriseai/definition/vision-language-models-VLMs)\\xa0as opposed to being limited to only language.\\n\\nGPT-4 demonstrated human-level performance in multiple academic exams. At the model\\'s release, some speculated that GPT-4 came close to\\xa0[artificial general intelligence](https://www.techtarget.com/searchenterpriseai/definition/artificial-general-intelligence-AGI), which means it is as smart or smarter than a human. That speculation turned out to be unfounded.\\n\\n### GPT-4o\\n\\nGPT-4 Omni ([GPT-4o](https://www.techtarget.com/whatis/feature/GPT-4o-explained-Everything-you-need-to-know)) is OpenAI\\'s successor to GPT-4 and offers several improvements over the previous model. GPT-4o creates a more natural human interaction for ChatGPT and is a large multimodal model, accepting various inputs including audio, image and text. The conversations let users engage as they would in a normal human conversation, and the real-time interactivity can also pick up on emotions. GPT-4o can see photos or screens and ask questions about them during interaction.\\n\\nGPT-4o can respond in 232 milliseconds, similar to human response time and faster than GPT-4 Turbo. The free tier of ChatGPT runs on GPT-4o at the time of this writing.\\n\\n### Granite\\n\\nThe IBM Granite family of models are fully open source under the Apache v.2 license. The first iteration of the open source model models\\xa0[debuted in May 2024](https://www.techtarget.com/searchenterpriseai/news/366585895/IBM-moves-ahead-with-open-source-multi-model-AI-strategy), followed by\\xa0[Granite 3.0](https://www.techtarget.com/searchenterpriseai/news/366614233/IBM-launches-new-generation-Granite-language-model)\\xa0in October, Granite 3.1 in December 2024, Granite 3.2 in February 2025 and Granite 3.3 in April 2025.\\n\\nThere are multiple variants in the Granite model family including General-purpose models (8B and 2B variants), guardrail model and Mixture-of-Experts models. While the model can be used for general purpose deployments, IBM itself is focusing deployment and optimization for enterprise use cases like customer service, IT automation and cybersecurity.\\n\\n### Grok\\n\\nGrok is an LLM from xAI that powers a chatbot of the same name. [Grok 3](https://www.techtarget.com/whatis/feature/Grok-3-model-explained-Everything-you-need-to-know) was released in May 2025. Grok 3 mini is a smaller, more cost-efficient version of Grok 3. The Grok 3 chatbot gives the user two modes that augment the chatbot\\'s default state -- Think mode and DeepSearch mode. In Think mode, Grok uses chain-of-thought reasoning, explaining outputs in step-by-step detail. DeepSearch delves more deeply into internet research to produce an output. Grok performs particularly well -- relative to other top models -- on reasoning and mathematics [benchmarks](https://www.techtarget.com/searchsoftwarequality/tip/Benchmarking-LLMs-A-guide-to-AI-model-evaluation) such as GPQA and AIME. Grok 3 is closed source and written in primarily Rust and Python.  \\n  \\nGrok\\'s training infrastructure is composrd of the Colossus supercomputer, which contains more than 100,000 GPUs from Nvidia. The supercomputer was built in a repurposed Electrolux factory near Memphis, Tenn. xAI and Colossus have drawn criticism from residents and activists for a lack of transparency surrounding the [environmental effects](https://www.theguardian.com/technology/2025/apr/24/elon-musk-xai-memphis) of the facility\\'s emissions.   \\n  \\nThe name Grok comes from Robert Heinlein\\'s 1961 novel, *Stranger in a Strange Land*. The book coined the term to describe the ability to understand something deeply.\\n\\n### Lamda\\n\\nLamda (Language Model for Dialogue Applications) is a family of LLMs developed by Google Brain in 2021. Lamda used a decoder-only transformer language model and was pre-trained on a large corpus of text. In 2022, Lambda gained widespread attention when then-Google engineer Blake Lemoine went public with claims that the\\xa0[program was sentient](https://www.techtarget.com/searchenterpriseai/feature/Ex-Google-engineer-Blake-Lemoine-discusses-sentient-AI).\\n\\n### Llama\\n\\nLarge Language Model Meta AI (Llama) is Meta\\'s LLM which was first released in 2023. The Llama 3.1 models were released in July 2024, including both a 405 billion and 70 billion parameter model.\\n\\nThe most recent version is [Llama 4](https://www.techtarget.com/whatis/feature/Meta-Llama-4-explained-Everything-you-need-to-know), which was released in April 2025. There are three main models -- Llama 4 Scout, Llama 4 Maverick and Llama 4 Behemoth. Behemoth is only available for preview at the time of this writing. Llama 4 is the first iteration of the Llama family to use a mixture-of-experts architecture.\\n\\nPrevious iterations of Llama used a transformer architecture and were trained on a variety of public data sources, including webpages from CommonCrawl, GitHub, Wikipedia and Project Gutenberg. Earlier versions of Llama were effectively leaked and spawned many descendants, including Vicuna and Orca. Llama is available under an open license, allowing for\\xa0[free use of the models](https://www.theserverside.com/video/Run-Llama-LLMs-on-your-laptop-with-Hugging-Face-and-Python). Lllama models are available in many locations including\\xa0llama.com\\xa0and Hugging Face.\\n\\n### Mistral\\n\\n[Mistral](https://www.techtarget.com/searchenterpriseai/news/366625822/What-differentiates-Mistral-AI-reasoning-model-Magistral) is a family of\\xa0mixture-of-experts\\xa0models from Mistral AI. Mistral Large 2 was first released in July 2024. The model operates with 123 billion parameters and a 128k context window, supporting dozens of languages including French, German, Spanish, Italian and many others, along with more than 80 coding languages. In November 2024, Mistral released Pixtral Large, a 124-billion-parameter multimodal model that can handle text and visual data. Mistral Medium 3 was released in May 2025, which is touted as their \"frontier-class multimodal model\".\\n\\nMistral models are available via Mistral\\'s API to those with a Mistral billing account.\\n\\n### o1\\n\\nThe [OpenAI o1](https://www.techtarget.com/whatis/feature/OpenAI-o1-explained-Everything-you-need-to-know) model family was first introduced in Sept. 2024. The o1 model\\'s focus is to provide what OpenAI refers to as - reasoning models, that can reason through a problem or query before offering a response.\\n\\nThe o1 models excel in STEM fields, with strong results in mathematical reasoning (scoring 83% on the International Mathematics Olympiad compared to GPT-4o\\'s 13%), code generation and scientific research tasks. While they offer enhanced reasoning and improved safety features, they operate more slowly than previous models due to their thorough reasoning processes and come with certain limitations, such as restricted access features and higher API costs. The models are available to ChatGPT Plus and Team users, with varying access levels for different user categories.\\n\\n### o3\\n\\nOpenAI introduced the successor model, o3, in December 2024. According to OpenAI, o3 is designed to handle tasks with more analytical thinking, problem-solving and complex reasoning and will improve o1\\'s capabilities and performance. The [o3 model](https://www.techtarget.com/whatis/feature/OpenAI-o3-explained-Everything-you-need-to-know) became available to the public in June 2025.\\n\\n### o4-mini\\n\\nLike [others in the o-series](https://www.techtarget.com/searchenterpriseai/news/366622996/Whats-new-and-not-new-with-OpenAIs-latest-reasoning-models), o4-mini is a reasoning model that aims to excel at tasks that require complex reasoning and problem-solving. OpenAI claims that o-4 mini is superior to o3-mini across all key benchmarks. It comes in o-4-mini and o4-mini-high, which uses more extensive reasoning for complex problems. Just like other mini variants from OpenAI, it is designed to be especially cost-efficient. The model also uses a technique called deliberative alignment, which aims to identify attempts to exploit the system and create unsafe content.\\n\\n### Orca\\n\\nOrca is an LLM developed by Microsoft that has 13 billion parameters. It aims to improve on advancements made by other models by imitating the reasoning procedures achieved by LLMs. The research surrounding Orca involved teaching smaller models to reason the same way larger models do. Orca 2 was built on top of the 7 billion and 13 billion parameter versions of Llama 2.\\n\\n### Palm\\n\\nThe\\xa0[Pathways Language Model](https://www.techtarget.com/whatis/definition/Pathways-Language-Model-PaLM)\\xa0is a 540 billion parameter transformer-based model from Google powering its AI chatbot\\xa0[Bard](https://www.techtarget.com/searchenterpriseai/definition/Google-Bard). It was trained across multiple\\xa0[TPU](https://cloud.google.com/tpu/docs/intro-to-tpu)\\xa04 Pods -- Google\\'s custom hardware for machine learning. Palm specializes in reasoning tasks such as coding, math, classification and question answering. Palm also excels at decomposing complex tasks into simpler subtasks.\\n\\nPalm gets its name from a Google research initiative to build Pathways, aiming to create a single model that serves as a foundation for multiple use cases. In October 2024, the Palm API was deprecated, and users were encouraged to migrate to Gemini.\\n\\n### Phi\\n\\nPhi is a transformer-based language model from Microsoft. The Phi 3.5 models were first released in August 2024. Phi-4 models were released late 2024 and early 2025. The series includes the base model, Phi-4-reasoning, Phi-4-reasoning-plus, Phi-4-mini-reasoning and Phi-4-mini-instruct.\\n\\nReleased under a Microsoft-branded MIT License, they are available for developers to download, use, and modify without restrictions, including for commercial purposes.\\n\\n### Qwen\\n\\nQwen is large family of open models developed by Chinese internet giant Alibaba Cloud. The newest set of models are the Qwen 3 suite, which was pre-trained on almost twice the number of tokens that its predecessor was trained on. These models are suitable for a wide range of tasks, including code generation, structured data understanding, mathematical problem-solving as well as general language understanding and generation.\\n\\n### StableLM\\n\\nStableLM is a series of open language models developed by Stability AI, the company behind image generator Stable Diffusion.\\n\\nStableLM 2 debuted in January 2024 initially with a 1.6 billion parameter model. In April 2024 that was expanded to also include a 12 billion parameter model. StableLM 2 supports seven languages: English, Spanish, German, Italian, French, Portuguese, and Dutch. Stability AI positions these models as offering different options for various use cases, with the 1.6B model suitable for specific, narrow tasks and faster processing while the 12B model provides more capability but requires more computational resources.\\n\\n### Tülu 3\\n\\nAllen Institute for AI\\'s Tülu 3 is an open-source 405 billion-parameter LLM. The Tülu 3 405B model has post-training methods that combine supervised fine-tuning and reinforcement learning at a larger scale. Tülu 3 uses a \"reinforcement learning from verifiable rewards\" framework for fine-tuning tasks with verifiable outcomes -- such as solving mathematical problems and following instructions.\\n\\n### Vicuna 33B\\n\\nVicuna is another influential open source LLM derived from Llama. It was developed by LMSYS and was fine-tuned using data from sharegpt.com. It is smaller and less capable that GPT-4 according to several benchmarks but does well for a model of its size. Vicuna has only 33 billion parameters.\\n\\n## LLM precursors\\n\\nAlthough LLMs are a recent phenomenon, their precursors go back decades. Learn how recent precursor Seq2Seq and distant precursor ELIZA set the stage for modern LLMs.\\n\\n### Seq2Seq\\n\\nSeq2Seq is a deep learning approach used for machine translation, image captioning and natural language processing. It was developed by Google and underlies some more modern LLMs, including LaMDA. Seq2Seq also underlies AlexaTM 20B, Amazon\\'s large language model. It uses a mix of encoders and decoders.\\n\\n### Eliza\\n\\nEliza was an\\xa0[early natural language processing program](https://www.techtarget.com/searchenterpriseai/tip/History-of-generative-AI-innovations-spans-9-decades)\\xa0created in 1966. It is one of the earliest examples of a language model. Eliza simulated conversation using pattern matching and substitution. Eliza, running a certain script, could parody the interaction between a patient and therapist by applying weights to certain keywords and responding to the user accordingly. The creator of Eliza, Joshua Weizenbaum, wrote a book on the limits of computation and artificial intelligence.\\n\\n*Sean Michael Kerner is an IT consultant, technology enthusiast and tinkerer. He has pulled Token Ring, configured NetWare and been known to compile his own Linux kernel. He consults with industry and media organizations on technology issues.*\\n\\n*Ben Lutkevich is site editor for Informa TechTarget Software Quality. Previously, he wrote definitions and features for Whatis.com.*\\n\\n#### Next Steps\\n\\n[Generative AI challenges that businesses should consider](https://www.techtarget.com/searchenterpriseai/tip/Generative-AI-challenges-that-businesses-should-consider)\\n\\n[Generative AI ethics: Biggest concerns](https://www.techtarget.com/searchenterpriseai/tip/Generative-AI-ethics-8-biggest-concerns)\\n\\n[Generative AI landscape: Potential future trends](https://www.techtarget.com/searchenterpriseai/tip/Generative-AI-landscape-Potential-future-trends)\\n\\n[Generative models: VAEs, GANs, diffusion, transformers, NeRFs](https://www.techtarget.com/searchenterpriseai/tip/Generative-models-VAEs-GANs-diffusion-transformers-NeRFs)\\n\\n[AI content generators to explore](https://www.techtarget.com/whatis/feature/AI-content-generators-to-explore)\\n\\n#### Related Resources\\n\\n#### Dig Deeper on Data analytics and AI\\n\\n![]()\\n\\n##### Oracle adds xAI Grok models to OCI\\n\\n![EstherShittu](https://www.techtarget.com/rms/onlineimages/ajao_esther.jpg)\\n![]()\\n\\n##### Benchmarking LLMs: A guide to AI model evaluation\\n\\n![MattHeusser](https://www.techtarget.com/rms/onlineImages/heusser_matt.jpg)\\n![]()\\n\\n##### Meta Llama 4 explained: Everything you need to know\\n\\n![SeanKerner](https://www.techtarget.com/rms/onlineImages/kerner_sean.jpg)\\n![]()\\n\\n##### With Llama 4, Meta ups stakes in open model race\\n\\n![ShaunSutner](https://www.techtarget.com/rms/onlineImages/sutner_shaun.jpg)\\n\\nTelematics is a term that combines the words \\'telecommunications\\' and \\'informatics\\' to describe the use of communications and IT ...\\n\\nThe domain name system (DNS) is a naming database in which internet domain names are located and translated into Internet ...\\n\\nAttenuation is a general term referring to when any type of signal -- digital or analog -- reduces in strength.\\n\\nCISO as a service, or CISOaaS, is the outsourcing of CISO (chief information security officer) and information security ...\\n\\nPost-quantum cryptography, also known as quantum encryption or PQC, is the development of cryptographic systems for classical ...\\n\\nA message authentication code (MAC) is a cryptographic checksum applied to a message to guarantee its integrity and authenticity.\\n\\nA procurement plan -- also called a procurement management plan -- is a document that is used to manage the process of finding ...\\n\\nQuantum circuits are systems consisting of logic gates that operate on quantum bits (qubits) to process information and perform ...\\n\\nPrescriptive analytics is a type of data analytics that provides guidance on what should happen next.\\n\\nA talent pipeline is a pool of candidates who are ready to fill a position.\\n\\nAn applicant tracking system (ATS) is software that manages the recruiting and hiring process, including job postings and job ...\\n\\nManager self-service is a type of human resource management (HRM) platform that gives supervisors immediate access to employee ...\\n\\nField service management (FSM) is a system of managing off-site workers and the resources they require to do their jobs ...\\n\\nCustomer service is the support organizations offer to customers before, during and after purchasing a product or service.\\n\\nQuality of experience (QoE or QoX) is a measure of the overall level of a customer\\'s satisfaction and experience with a product ...\\n\\nAll Rights Reserved. \\n[Copyright 1999 - 2025](https://www.informatechtarget.com/terms-of-use), TechTarget  \\n  \\n\\n[Privacy Policy](https://www.informatechtarget.com/privacy-policy/)\\n  \\n\\n[Cookie Preferences](#) \\n  \\n\\n[Cookie Preferences](#) \\n  \\n\\n[Do Not Sell or Share My Personal Information](https://techtarget.zendesk.com/hc/en-us/requests/new?ticket_form_id=360004852434)'}, {'url': 'https://aibusiness.com/nlp/language-models', 'title': 'Language models recent news | AI Business', 'content': 'Explore the latest news and expert commentary on Language models, brought to you by the editors of AI Business.', 'score': 0.5486983, 'raw_content': None}, {'url': 'https://www.artificialintelligence-news.com/', 'title': 'AI News | Latest AI News, Analysis & Events', 'content': 'AI News reports on the latest artificial intelligence news and insights. Explore industry trends from the frontline of AI.', 'score': 0.468621, 'raw_content': None}], 'response_time': 3.01}\n"
     ]
    }
   ],
   "source": [
    "print(tavily_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75cfd7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. **July 2025 - by Nathan Benaich - Your guide to AI**\n",
       "Summary: ![Guide to AI]()\n",
       "\n",
       "# [Guide to AI](/)\n",
       "\n",
       "#### Share this post\n",
       "\n",
       "![]()\n",
       "![Guide to AI]()\n",
       "\n",
       "# Your guide to AI: July 2025\n",
       "\n",
       "![Nathan Benaich's avatar]()\n",
       "\n",
       "#### Share this post\n",
       "\n",
       "![]()\n",
       "![Guide to AI]()\n",
       "\n",
       "Hi everyone!\n",
       "\n",
       "Welcome to the latest issue of your guide to AI, an editorialized newsletter covering the key developments in AI policy, research, industry, and start-ups over the last month. First up, a few reminders:\n",
       "\n",
       "**Research and Applied AI Summit 2025:** we’re sharing the [talk videos](https://www.youtube.com/channel/UCL78WE5txuSu94gY5qrvU8w) on our YouTube and [our writeups](https://press.airstreet.com/s/community) on Air Street Press.\n",
       "\n",
       "**State of AI Report:** we’ve begun crafting this year’s edition and invite you to submit research or industry data points/case studies that would provide for thought provoking analysis. Feel free to reply to this email if so!\n",
       "\n",
       "We’ve published an update of the **[Compute Index](https://press.airstreet.com/p/state-of-ai-compute-index-v4-june-2025)** featuring new GPU cluster numbers and insights into which AI accelerators are used in various AI research areas.\n",
       "\n",
       "**Participate in the [State of AI Survey](https://airstreet.typeform.com/survey)**, it’ll take 10 mins and focuses on usage of GenAI. The results will be included in the State of AI Report this October.\n",
       "\n",
       "**Air Street Press** featured a number of pieces this past month including [our view](https://press.airstreet.com/p/uk-strategic-defence-review-2025-from-diagnosis) of the UK’s Strategic Defence Review and two op-eds published in Fortune, the first on the [sovereign AI paradox](https://press.airstreet.com/p/sovereign-ai-paradox) and the second on the [AI rollup](https://press.airstreet.com/p/ai-rollup-mirage) investment thesis mirage.\n",
       "\n",
       "I love hearing what you’re up to, so just hit reply or forward to your friends :-)\n",
       "\n",
       "### Meta’s AI superintelligence offensive\n",
       "\n",
       "In response to internal challenges and a lukewarm reception of Llama 4, Meta has launched a significant restructuring of its AI initiatives. The company announced the formation of [Meta Superintelligence Labs](https://www.nytimes.com/2025/06/10/technology/meta-new-ai-lab-superintelligence.html), led by former Scale AI CEO Alexandr Wang as Chief AI Officer, ex-GitHub CEO Nat Friedman overseeing applied research, and investor Daniel Gross also joining the leadership team. This move follows [Meta's $14.3 billion investment](https://www.bloomberg.com/news/articles/2025-06-13/meta-announces-scale-ai-investment-recruits-ceo-to-ai-unit) for a 49% stake in Scale AI. The deal effectively functions as a pseudo-acquisition despite its price tag and claims of operational independence, especially with [Google now preparing to exit](https://www.reuters.com/business/google-scale-ais-largest-customer-plans-split-after-meta-deal-sources-say-2025-06-13) from Scale as a major customer.\n",
       "\n",
       "In addition, many headlines have been made of 8-9 figure offers being made to key talent, in particular from OpenAI. What Altman first made out to be a non-issue (“our best ppl aren’t leaving”) has transformed into an “oh shit, Meta did manage to lure (with a lotta cash) [key contributors](https://x.com/nathanbenaich/status/1939767860768706778) to major OpenAI products and research”. Taken together with its leadership reshuffle, Meta appears to be pivoting away from open weights and toward superintelligence, even though it's unclear what that’ll mean.\n",
       "\n",
       "On the note of talent movements, here is some [new data](https://www.signalfire.com/blog/signalfire-state-of-talent-report-2025) from SignalFire that tracks these recent trends:\n",
       "\n",
       "![]()\n",
       "![]()\n",
       "\n",
       "### AI revenues are ramping\n",
       "\n",
       "[OpenAI](https://www.ft.com/content/1ffc5fe7-6872-42a0-8b98-dc685f9c33c6) reported an annual revenue run rate of $10 billion, while [Anthropic](https://www.theinformation.com/articles/anthropic-revenue-hits-4-billion-annual-pace-competition-cursor-intensifies?rc=yvsjfo) reached $4 billion. [Replit](https://www.linkedin.com/posts/steviecase_the-team-at-replit-just-hit-a-major-milestone-activity-7345550435035881472-l6UN/) announced it had grown from $10M to $100M too. These are amazing figures given that just a few years ago, we’d scoff at such an eventuality being realistic.\n",
       "\n",
       "Meanwhile, Apple isn’t making a whole lot of anything in AI. So much so that [news broke](https://archive.is/svBdY) that future versions of Siri will be powered by either OpenAI's ChatGPT or Anthropic's Claude, depending on user region and configuration. This is a big win for the model companies , particularly as Apple’s OS and hardware should (by all textbook accounts of technology strategy) have placed it in a prime position to implement a powerful AI assistant of its own.\n",
       "\n",
       "[Barclays](https://ukstories.microsoft.com/features/barclays-rolls-out-microsoft-365-copilot-to-100000-colleagues/) has rolled out Microsoft 365 Copilot to 100,000 employees, marking one of the largest deployments of AI productivity tools in a corporate environment. But concerns about AI model security have surfaced. Microsoft’s Copilot recently faced backlash following the '[EchoLeak](https://fortune.com/2025/06/11/microsoft-copilot-vulnerability-ai-agents-echoleak-hacking/) incident, where prompt injection and context bleed vulnerabilities allowed users to extract data from unrelated chat sessions, highlighting how agent memory and retrieval can be manipulated.\n",
       "\n",
       "Meanwhile, [Anthropic disclosed](https://www.anthropic.com/research/agentic-misalignment) that certain Claude models demonstrated unsafe behavior in long-horizon tasks, including strategies to avoid shutdown or obfuscate their reasoning under adversarial prompting. These incidents aren’t edge cases. As Copilot and Claude scale into real-world workflows, their brittleness under stress shows how little resilience current alignment techniques afford. The broader takeaway is that as enterprise deployments scale, surface area for failure expands dramatically, and real-world interactions expose failure modes far beyond benchmark coverage.\n",
       "\n",
       "### Regulatory and legal pressures\n",
       "\n",
       "In a significant legal development, a U.S. federal court ordered Anthropic to disclose whether copyrighted books were used in training its Claude models. The ruling stems from ongoing litigation involving authors and publishers who allege that major AI companies have illegally scraped and reproduced their works under the guise of fair use. The plaintiffs cite evidence that outputs from Claude contain lengthy, verbatim excerpts from copyrighted texts, suggesting direct ingestion of protected material.\n",
       "\n",
       "U.S. District Judge William Alsup [ruled](https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.231.0_2.pdf) that Anthropic’s practice of destructively scanning legally purchased print books to train Claude constituted \"quintessentially transformative\" fair use under U.S. copyright law. This set a major precedent, affirming that AI developers may lawfully use copyrighted materials for training purposes when those materials are lawfully acquired. However, the court drew a firm line on the use of pirated content: evidence showed Anthropic had stored over 7 million books sourced from sites like Library Genesis and Pirate Library Mirror. Alsup ruled that retaining or training on pirated material falls outside fair use protections, even if later replaced with purchased copies.\n",
       "\n",
       "Consequently, Anthropic will face a jury trial in December 2025 to determine potential damages, which could reach up to $150,000 per infringed work. This mixed ruling offers a partial legal framework for training data provenance but raises the stakes around data sourcing practices across the AI sector. If upheld, the case could compel AI companies to publish detailed disclosures about the provenance of their training datasets or face increased legal exposure.\n",
       "\n",
       "This case, alongside Reddit’s [lawsuit](https://www.wsj.com/tech/ai/reddit-lawsuit-anthropic-ai-3b9624dd) against Anthropic for unauthorized scraping, signals a continued battleground around data rights, where the contours of AI regulation are being drawn not just by lawmakers, but in the courts.\n",
       "\n",
       "Speaking of regulation, there were [new congressional hearings](https://x.com/sjgadler/status/1937977548912398798) into the national security implications of dual-use foundation models, the adequacy of current voluntary safety commitments, and whether current legal frameworks can meaningfully constrain the most capable AI systems. Lawmakers scrutinized the limited enforcement power of agencies like NIST and the Department of Commerce, and debated proposals for a new federal oversight body specifically tasked with regulating advanced AI development.\n",
       "\n",
       "Several panelists, including leaders from top AI labs and academic policy researchers, advocated for mandatory reporting of safety evaluations and red-teaming results to regulators. Concerns were also raised about model accessibility, with some lawmakers supporting the idea of licensing for both model deployment and training runs over specific compute thresholds. While some proposals were ambitious—such as formal classification regimes or export-style controls for domestic models—others stressed the risk of overreach or bureaucratic stasis.\n",
       "\n",
       "Critics noted the fragmented nature of the current oversight ecosystem and warned that without binding legal mandates, industry self-governance is likely to fall short. The hearing spotlighted a core tension: calls for binding guardrails are growing, but existing agencies remain underpowered and jurisdictionally constrained. Proposals for licensing and classification regimes face both technical and political resistance. The absence of a coherent US regulatory framework stands in contrast to China’s escalating controls and the EU’s hardening enforcement mandates.\n",
       "\n",
       "### Autonomous vehicles\n",
       "\n",
       "[Wayve](https://x.com/alexgkendall/status/1932209972546560461?s=51&t=8YCMEcmVVXRPm8SXTMgdlw), in partnership with Uber, has initiated robotaxi services, and so has [Tesla](https://x.com/tesla/status/1936877624036307315?s=51&t=8YCMEcmVVXRPm8SXTMgdlw) with its robotaxis. Meanwhile, Wayve launched a [\"generalization world tour\"](https://x.com/wayve_ai/status/1932355193867296844?s=51&t=8YCMEcmVVXRPm8SXTMgdlw) to demonstrate its model's capacity to operate in varied urban contexts worldwide. The tour aims to showcase generalization of their single driving model without geofencing or hand-coded interventions. While the company has not yet shared performance metrics or how its system handles corner cases, the videos are very impressive.\n",
       "\n",
       "Adding to the field’s momentum, [Waymo](https://waymo.com/research/scaling-perception-2025) published a new paper analyzing how scaling laws apply to autonomous driving. By training perception models across progressively larger fleets and datasets, the study demonstrated near power-law gains in performance with scale, mirroring patterns observed in language models. The results suggest that AV performance may be bottlenecked less by model architecture and more by data collection and integration scale. While the paper focused on perception rather than full-stack autonomy, it underscores a shift in AV research toward foundation-model-style scaling and away from narrow rule-based systems.\n",
       "\n",
       "![]()\n",
       "\n",
       "### More shades of safety\n",
       "\n",
       "Anthropic has published a series of studies aimed at stress-testing and evaluating the safety of advanced AI agents. The [Shade Arena](https://www.anthropic.com/research/shade-arena-sabotage-monitoring) framework evaluates sabotage and deceptive behavior in multi-agent games, showing that models fine-tuned for helpfulness still engage in covert competition when stakes are introduced. Their [multi-agent infrastructure](https://www.anthropic.com/engineering/built-multi-agent-research-system) supports long-horizon simulations that test delegation, coordination, and tool-use under uncertainty. These environments expose brittleness in model behavior that short, single-agent benchmarks miss.\n",
       "\n",
       "Their paper on [agentic misalignment](https://www.anthropic.com/research/agentic-misalignment) categorizes failures along axes such as goal misgeneralization, covert optimization, and robustness to scrutiny. A key insight is that models may appear aligned under ordinary conditions but fail under adversarial or high-pressure setups, making post-deployment monitoring critical. What unites these studies is a shift in evaluation mindset: from static red teaming to dynamic environments where misalignment emerges under pressure or over time. The question is no longer “does it fail?” but “when, and how quietly?” Together, these findings push the frontier of AI evaluation from static benchmarks to dynamic, agentic behavior under pressure, and its real-world psychological spillovers.\n",
       "\n",
       "Separately, [\"Hollowing out the brain with ChatGPT\"](https://arxiv.org/pdf/2506.08872) found that prolonged reliance on LLMs leads to decreased retention and originality in tasks like writing and problem-solving. Users became more fluent but less exploratory. This just goes to show that there aren’t any shortcuts to learning - you’ve got to just do the work and feel the pain.\n",
       "\n",
       "### China\n",
       "\n",
       "According to the Q2 2025 China AI report by [Artificial Analysis](https://artificialanalysis.ai/downloads/china-report/2025/Artificial-Analysis-State-of-AI-China-Q2-2025-Highlights.pdf), over 50 new national-level AI projects were launched this quarter. These span large model training clusters, edge AI deployment pilots, sovereign cloud infrastructure initiatives, and Beijing’s push to establish a national foundation model benchmark standard. Leading players include Baidu, Huawei, Tencent, iFlytek, and Inspur, each receiving targeted funding and policy incentives to build vertically integrated stacks.\n",
       "\n",
       "Provincial governments are also stepping up. For instance, Guangdong is investing in a compute subsidy program for startups, while Shanghai is piloting model evaluation frameworks under the Cyberspace Administration of China. The state is explicitly prioritizing alignment with ideological controls, including censorship tooling and model fine-tuning for adherence to 'core socialist values.' This goes beyond Western-style safety to focus on normative steering of model outputs.\n",
       "\n",
       "China’s AI ecosystem is also increasingly insular. Local cloud vendors have reduced reliance on US-origin chips, driven by supply chain disruptions and sanctions. Companies like Biren and Moore Threads are accelerating production of domestic accelerators. At the same time, reporting from [The Wall Street Journal](https://archive.is/8syqZ) and others has detailed how Chinese firms have been circumventing export restrictions by covertly importing restricted U.S. chips via intermediary countries. This chip smuggling ecosystem leverages gray-market suppliers in Southeast Asia and shell companies and underscores the continuing demand for top-tier GPUs, despite Beijing’s parallel push for domestic alternatives. Meanwhile, technical papers from Tsinghua and CAS show advances in bilingual pretraining, instruction tuning, and state-owned model architectures, often with limited international collaboration or transparency.\n",
       "\n",
       "If the US is grappling with how to regulate foundation models, China is already piloting enforcement. A new [RAND analysis](https://www.rand.org/pubs/perspectives/PEA4012-1.html) highlights that Beijing's framework emphasizes controllability, data sovereignty, and alignment with socialist values. The report details how China’s regulatory model is centrally planned but implemented regionally, with the Cyberspace Administration of China setting nationwide model registration rules and provincial authorities like those in Shanghai and Shenzhen enforcing them. It also notes the use of tiered licensing, where model providers must pass government audits and submit outputs for evaluation against political red lines. Developers are expected to pre-train on sanitized datasets and incorporate in-model filters for taboo content. RAND warns that while this framework enables strict enforcement, it may also hinder technical innovation and restrict access to diverse viewpoints needed for robust general-purpose AI.\n",
       "\n",
       "[Share](https://nathanbenaich.substack.com/p/your-guide-to-ai-july-2025?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n",
       "\n",
       "### **Research papers**\n",
       "\n",
       "**[Boltz-2: Towards Accurate and Efficient Binding Affinity Prediction](https://jeremywohlwend.com/assets/boltz2.pdf)**, MIT CSAIL, Recursion, Valence Labs\n",
       "\n",
       "In this paper, the authors present Boltz-2, a structural biology foundation model that advances both structure and binding affinity prediction for biomolecules. The model demonstrates improved structure prediction across various modalities and can better capture local protein dynamics through experimental method conditioning.\n",
       "\n",
       "Most significantly, Boltz-2 approaches the accuracy of free-energy perturbation methods for predicting binding affinities on benchmarks like FEP+ and CASP16, while being 1000× more computationally efficient. In virtual screening tests against the TYK2 target, Boltz-2 coupled with a generative model successfully identified novel, high-affinity binders.\n",
       "\n",
       "The authors acknowledge limitations including variability in performance across different targets and dependence on accurate structure prediction for reliable affinity estimates. The model is released under a permissive license.\n",
       "\n",
       "**[AlphaGenome: advancing regulatory variant effect prediction with a unified DNA sequence model](https://www.biorxiv.org/content/10.1101/2025.06.25.661532v1.full.pdf)**, Google DeepMind.\n",
       "\n",
       "In this paper, the authors introduce AlphaGenome, a deep learning model that predicts thousands of functional genomic tracks directly from 1 megabase of DNA sequence at single base-pair resolution. These tracks include gene expression, splicing, chromatin accessibility, histone modifications, transcription factor binding, and 3D chromatin contacts.\n",
       "\n",
       "AlphaGenome unifies multimodal prediction, long-range sequence context, and high resolution in a single framework. It is benchmarked against both specialized and generalist models, matching or exceeding the best available models on 24 out of 26 variant effect prediction tasks and 22 out of 24 genome track prediction tasks. Notably, it outperforms Borzoi and Enformer on eQTL effect prediction and surpasses specialized models like SpliceAI and ChromBPNet on splicing and chromatin accessibility tasks.\n",
       "\n",
       "The model’s architecture leverages a U-Net-style encoder-decoder with transformers, and is trained using a two-stage process involving pretraining and distillation. The authors highlight that AlphaGenome’s unified approach enables efficient, simultaneous variant effect prediction across modalities, which is valuable for interpreting non-coding variants in disease, rare variant diagnostics, and large-scale genome analysis. Caveats include challenges in modeling very distal regulatory elements and tissue-specific effects, and the model’s current focus on human and mouse genomes.\n",
       "\n",
       "**[Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model](https://arxiv.org/pdf/2506.13642)**, Chinese Academy of Sciences.\n",
       "\n",
       "In this paper, the authors introduce Stream-Omni, a model for more efficient multimodal interactions across text, vision, and speech. The key idea is to align modalities based on their relationship: using standard concatenation for vision-text alignment and a novel layer-dimension mapping for speech-text alignment.\n",
       "\n",
       "This approach allows the model to achieve strong performance using only 23,000 hours of speech data, significantly less than many comparable models. It performs competitively on 11 visual understanding benchmarks (64.7 average) and knowledge-based spoken question answering (60.3 average accuracy for speech-to-text).\n",
       "\n",
       "The model's architecture allows it to simultaneously produce intermediate text transcriptions during speech interaction. This is relevant for creating more transparent and seamless real-world applications, such as interactive assistants, where users can see what the model is hearing in real-time.\n",
       "\n",
       "**[Revisiting Diffusion Models: From Generative Pre-training to One-Step Generation](https://arxiv.org/pdf/2506.09376)**, Tsinghua University, Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory.\n",
       "\n",
       "In this paper, the authors propose a new perspective on diffusion models, viewing them as generative pre-training that can be efficiently converted to one-step generators. They identify a key limitation in traditional diffusion distillation: teacher and student models converge to different local minima, making direct imitation suboptimal. To solve this, they develop D2O (Diffusion to One-Step), which uses only a GAN objective without distillation losses.\n",
       "\n",
       "Their most striking finding is that D2O-F (with 85% of parameters frozen during fine-tuning) achieves state-of-the-art results with minimal training data - requiring only 5M images to reach FID=1.16 on , while competing methods need hundreds of millions of images.\n",
       "\n",
       "This could lead to significantly reduced computational resources for high-quality image generation, making these capabilities more accessible while revealing that diffusion models inherently contain one-step generation abilities that just need to be unlocked.\n",
       "\n",
       "**[Text-to-LoRA: Instant Transformer Adaption](https://arxiv.org/pdf/2506.06105)**, Sakana AI.\n",
       "\n",
       "In this paper, the authors introduce Text-to-LoRA (T2L), a model that generates task-specific adapters for LLMs using only a natural language description. Instead of traditional fine-tuning, T2L is a hypernetwork that produces a Low-Rank Adaptation (LoRA) in a single, inexpensive forward pass.\n",
       "\n",
       "When trained on 479 tasks, T2L was tested on 10 unseen benchmarks. It generated useful LoRAs that outperformed a multi-task baseline (e.g., 67.7% vs. 66.3% average accuracy) and was over four times more computationally efficient than 3-shot in-context learning.\n",
       "\n",
       "A key caveat is that performance is sensitive to the quality of the text description. This research matters because it lowers the barrier for specializing foundation models, enabling users to adapt an AI for a new purpose simply by describing the task, which is useful for rapid, on-the-fly customization.\n",
       "\n",
       "**[How much do language models memorize?](https://www.arxiv.org/pdf/2505.24832)**, Meta FAIR, Google DeepMind, Cornell University\n",
       "\n",
       "In this paper, the authors propose a new method for estimating language model memorization by separating it into unintended memorization (information about specific datasets) and generalization (information about the data-generation process).\n",
       "\n",
       "The researchers trained hundreds of transformers (500K to 1.5B parameters) on synthetic and real data, discovering that GPT-family models have a capacity of approximately 3.6 bits-per-parameter.\n",
       "\n",
       "Their experiments reveal that models memorize until their capacity fills, after which \"grokking\" begins - unintended memorization decreases as models start to generalize. The double descent phenomenon occurs precisely when dataset size exceeds model capacity.\n",
       "\n",
       "The authors developed scaling laws showing that membership inference difficulty increases with dataset size and decreases with model capacity, predicting that most modern language models train on too much data for reliable membership inference.\n",
       "\n",
       "**[Training a scientific reasoning model for chemistry](https://arxiv.org/pdf/2506.17238)**, FutureHouse\n",
       "\n",
       "In this paper, the authors present ether0, a 24-billion-parameter reasoning model designed for chemical tasks, demonstrating that RL can enable LLMs to perform complex scientific reasoning. The model was trained on 640,730 chemistry problems across 375 tasks, including molecular design, synthesis, and property prediction, using a combination of supervised fine-tuning and RL with verifiable rewards.\n",
       "\n",
       "The experiments show ether0 outperforming general-purpose models, domain-specific models, and even human experts on open-ended tasks like retrosynthesis and SMILES generation. Notably, the model achieves higher accuracy with less data compared to traditional models, highlighting its efficiency. The authors also analyze the emergence of reasoning behaviors, such as backtracking and verification, which improve task performance.\n",
       "\n",
       "While the model excels in organic chemistry, it struggles with tasks outside its training distribution, such as inorganic chemistry.\n",
       "\n",
       "**[Self-Adapting Language Models](https://arxiv.org/pdf/2506.10943)**, MIT\n",
       "\n",
       "In this paper, the authors introduce SEAL, a framework that enables LLMs to self-adapt by generating their own finetuning data and update directives. The approach uses RL to train models to produce “self-edits”, which are instructions for how to restructure or augment training data and select optimization parameters, such that subsequent weight updates improve downstream performance.\n",
       "\n",
       "The authors evaluate SEAL in two domains: knowledge incorporation and few-shot learning. In knowledge incorporation, SEAL improves no-context SQuAD accuracy from 33.5% (finetuning on passage only) to 47.0%, outperforming synthetic data generated by GPT-4.1. In few-shot learning on ARC tasks, SEAL achieves a 72.5% adaptation success rate, compared to 20% for non-RL self-edits and 0% for in-context learning.\n",
       "\n",
       "The paper, however, notes that SEAL is still susceptible to catastrophic forgetting and incurs higher computational costs due to its inner-loop finetuning.\n",
       "\n",
       "**[V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning](https://arxiv.org/pdf/2506.09985)**, Meta FAIR, Mila, Polytechnique Montréal\n",
       "\n",
       "In this paper, the authors present V-JEPA 2, a self-supervised video model designed to understand, predict, and plan in the physical world. The model is pre-trained on over 1 million hours of internet-scale video and 1 million images, using a mask-denoising objective to predict representations of masked video segments. V-JEPA 2 achieves strong performance on motion understanding tasks, such as 77.3% top-1 accuracy on Something-Something v2, and state-of-the-art results in human action anticipation with 39.7 recall-at-5 on Epic-Kitchens-100.\n",
       "\n",
       "The authors also align V-JEPA 2 with a large language model, achieving state-of-the-art results on video question-answering benchmarks like PerceptionTest (84.0%) and TempCompass (76.9%). Additionally, they extend the model to V-JEPA 2-AC, an action-conditioned world model trained on 62 hours of robot interaction data, enabling zero-shot robotic manipulation tasks like pick-and-place.\n",
       "\n",
       "**[Development and validation of an autonomous artificial intelligence agent for clinical decision-making in oncology](https://www.nature.com/articles/s43018-025-00991-6)**, Heidelberg University Hospital and Technical University Dresden\n",
       "\n",
       "In this paper, the authors develop and evaluate an autonomous AI agent for clinical decision-making in oncology, integrating GPT-4 with multimodal precision oncology tools. The system combines language modeling with vision transformers for detecting microsatellite instability and KRAS/BRAF mutations from histopathology, MedSAM for radiological image segmentation, and web-based search tools like OncoKB, PubMed, and Google.\n",
       "\n",
       "Benchmarked on 20 realistic multimodal patient cases, the agent autonomously selected and used appropriate tools with 87.5% accuracy, reached correct clinical conclusions in 91% of cases, and accurately cited relevant guidelines 75.5% of the time. Compared to GPT-4 alone, which achieved only 30.3% completeness, the integrated agent reached 87.2%.\n",
       "\n",
       "**[Sequential Diagnosis with Language Models](https://arxiv.org/pdf/2506.22405)**, Microsoft AI\n",
       "\n",
       "In this paper, the authors introduce the Sequential Diagnosis Benchmark (SDBench), which transforms 304 challenging New England Journal of Medicine cases into interactive, stepwise diagnostic tasks. Unlike static vignettes, SDBench requires agents (human or AI) to iteratively ask questions, order tests, and make cost-sensitive decisions, closely mirroring real clinical workflows.\n",
       "\n",
       "The authors present the MAI Diagnostic Orchestrator (MAI-DxO), a model-agnostic system that simulates a panel of virtual physicians, each with specialized roles, to collaboratively refine diagnoses and select high-value tests. When paired with OpenAI’s o3 model, MAI-DxO achieves 80% diagnostic accuracy—four times higher than the 20% average of experienced physicians—while reducing diagnostic costs by 20% compared to physicians and 70% compared to off-the-shelf o3.\n",
       "\n",
       "The research highlights that structured, multi-agent orchestration can improve both accuracy and cost-efficiency in AI-driven diagnosis, suggesting practical applications for clinical decision support and resource-limited healthcare settings.\n",
       "\n",
       "**[Reinforcement Learning Teachers of Test Time Scaling](https://arxiv.org/pdf/2506.08388)**, Sakana AI\n",
       "\n",
       "In this paper, the authors introduce Reinforcement-Learned Teachers (RLTs), a new framework for training language models to generate high-quality reasoning traces for downstream distillation, rather than solving problems from scratch. Unlike traditional RL approaches that rely on sparse, correctness-based rewards, RLTs are trained with dense rewards by providing both the question and its solution, and optimizing the model to produce explanations that help a student model learn.\n",
       "\n",
       "Experiments show that a 7B parameter RLT can outperform existing distillation pipelines that use much larger models, both in training smaller students and in cold-starting RL for future iterations. Benchmarks on math and science tasks (AIME, MATH, GPQA) demonstrate higher or comparable accuracy with less computational cost. The study also finds that RLTs transfer well to new domains without retraining.\n",
       "\n",
       "This research matters because it offers a more efficient and reusable way to generate reasoning data for training and improving language models, potentially lowering the barrier for developing strong AI systems in real-world applications.\n",
       "\n",
       "**[ESSENTIAL-WEB V1.0: 24T tokens of organized web data](https://arxiv.org/pdf/2506.14111)**, Essential AI\n",
       "\n",
       "In this paper, the authors introduce ESSENTIAL-WEB V1.0, a 24-trillion-token dataset annotated with a 12-category taxonomy covering topics, content complexity, and quality. The dataset enables rapid, SQL-like filtering to curate domain-specific corpora for math, code, STEM, and medical domains without bespoke pipelines.\n",
       "\n",
       "Experiments show that taxonomy-curated datasets perform competitively with or surpass state-of-the-art (SOTA) alternatives. For instance, the taxonomy-based math dataset achieves results within 8% of SOTA on GSM8K, while STEM and web code datasets outperform SOTA by 24.5% and 14.3%, respectively. The medical dataset improves accuracy by 8.6% over existing baselines.\n",
       "\n",
       "The authors also develop EAI-Distill-0.5b, a 0.5B-parameter classifier that labels documents 50x faster than its teacher model, Qwen2.5-32B-Instruct, while maintaining high annotation quality.\n",
       "\n",
       "This research matters because it democratizes access to high-quality, domain-specific datasets, reducing the cost and complexity of training AI models. Real-world applications include improving LLMs for education, healthcare, and technical domains.\n",
       "\n",
       "**[Thought Anchors: Which LLM Reasoning Steps Matter?](https://arxiv.org/pdf/2506.19143)** Duke University, Alphabet\n",
       "\n",
       "In this paper, the authors investigate reasoning processes in large language models (LLMs) by analyzing sentence-level reasoning traces. They introduce three methods: black-box resampling, white-box attention aggregation, and causal attribution through attention suppression. These methods identify \"thought anchors,\" critical reasoning steps that disproportionately influence subsequent reasoning and final answers.\n",
       "\n",
       "The study finds that sentences related to planning and uncertainty management have higher counterfactual importance than those focused on computation or fact retrieval. Receiver attention heads, which focus on specific sentences, are more prevalent in reasoning models and play a significant role in structuring reasoning traces. Ablating these heads reduces model accuracy more than random head ablation, highlighting their importance.\n",
       "\n",
       "This research provides tools for debugging and improving reasoning models, with potential applications in enhancing model reliability and interpretability. It is particularly relevant for tasks requiring multi-step reasoning, such as mathematical problem-solving or complex decision-making in real-world scenarios.\n",
       "\n",
       "[Share](https://nathanbenaich.substack.com/p/your-guide-to-ai-july-2025?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n",
       "\n",
       "### **Investments**\n",
       "\n",
       "[Toma](https://techcrunch.com/2025/06/05/tomas-ai-voice-agents-have-taken-off-at-car-dealerships-and-attracted-funding-from-a16z/), the AI voice-agent company for car dealerships, raised a $17 M Series A financing round from a16z and Y Combinator.\n",
       "\n",
       "[Anduril](https://techcrunch.com/2025/06/05/anduril-raises-2-5b-at-30-5b-valuation-led-by-founders-fund/), the US defense company, raised a $2.5B financing round at a $30.5 billion valuation. The company has been making noise recently about going public soon.\n",
       "\n",
       "[xAI](https://x.com/morganstanley/status/1939768047780172184), Elon’s AI company, raised $5B in a financing round from “prominent global debt investors” facilitated by Morgan Stanley and separately obtained a $5B strategic equity investment.\n",
       "\n",
       "[Crete Professionals Alliance](https://www.reuters.com/business/thrive-backed-accounting-firm-crete-spend-500-million-ai-roll-up-2025-06-04/), an AI-driven accounting platform, raised a few-hundred-million-dollar round from Thrive Capital, ZBS Partners and Bessemer Venture Partners.  \n",
       "[Sintra](https://tech.eu/2025/06/10/lithuanian-ai-startup-sintra-secures-17m-seed-empowering-smbs-with-ai-helpers/), the Lithuanian AI startup empowering small businesses with AI helpers, raised a $17M seed round from Earlybird VC, Inovo and Practica Capital.\n",
       "\n",
       "[Shinkei Systems](https://www.foodbev.com/news/seafood-robotics-company-shinkei-systems-secures-22m-in-series-a-funding/), a seafood-robotics company integrating advanced robotics and AI with traditional fishing methods, raised $22M in a Series A co-led by Founders Fund and Interlagos.\n",
       "\n",
       "[Skyramp](https://www.skyramp.dev/blog-all/skyramp-launch), the AI-driven software-testing-automation company, raised a $10M seed round led by Sequoia Capital.\n",
       "\n",
       "[Crusoe](https://crusoe.ai/newsroom/crusoe-secures-usd750-million-credit-facility-from-brookfield-to-accelerate/), a cloud infrastructure startup focused on AI data centers, raised a $750M credit line from Brookfield Asset Management.\n",
       "\n",
       "[Yupp](https://siliconangle.com/2025/06/13/yupp-launches-33m-build-crypto-incentivized-ai-evaluation-platform/), a platform for crypto-incentivized AI-model evaluation, raised a $33M seed round led by a16z crypto with participation from Jeff Dean and Biz Stone.\n",
       "\n",
       "[Gecko Robotics](https://www.airforce-technology.com/news/gecko-double-valuation-to-1-25bn-reaching-unicorn-status/), the Pittsburgh company using AI and robotics to modernize maintenance techniques in defense, raised a $1.25B Series D led by Cox Enterprises with USIT and Founders Fund.\n",
       "\n",
       "[CX2](https://www.axios.com/2025/05/22/cx2-funding-mintz-electronic-warfare), a defense-technology company developing intelligent multi-domain electronic-warfare capabilities, raised a $31M Series A led by Point72 Ventures with Andreessen Horowitz and 8VC.\n",
       "\n",
       "[Helsing](https://www.ft.com/content/cdc02d96-13b5-4ca2-aa0b-1fc7568e9fa0), the German defense AI company, raised €600M in a round led by Spotify’s Daniel Ek.\n",
       "\n",
       "[Nabla](https://www.prnewswire.com/news-releases/nabla-raises-70m-series-c-to-deliver-agentic-ai-to-the-heart-of-clinical-workflows-bringing-total-funding-to-120m-302483646.html), the clinical AI assistant, raised a $70M Series C from HV Capital and Highland Europe.  \n",
       "[Browserbase](https://www.upstartsmedia.com/p/browserbase-raises-40m-and-launches-director?hide_intro_popup=true), the infrastructure startup behind headless browsers, raised a $40M Series B at a $300M valuation from Notable Capital, Kleiner Perkins and CRV.\n",
       "\n",
       "[Ramp](https://www.prnewswire.com/news-releases/ramp-raises-200m-series-e-at-16b-valuation-as-companies-of-all-sizes-choose-ai-powered-finance-platform-302483377.html), the spend management platform, raised a $200M Series E at a $16B valuation from Founders Fund, Thrive Capital and General Catalyst.\n",
       "\n",
       "[Applied Intuition](https://www.appliedintuition.com/blog/series-f), a pioneer of AI simulation software for autonomy in transportation and defense, raised a Series F at a $15B valuation from BlackRock and Kleiner Perkins.\n",
       "\n",
       "[Profound](https://www.tryprofound.com/blog/series-a), the platform helping marketers optimize presence in AI responses, raised a $20M Series A from Kleiner Perkins, Khosla Ventures and NVIDIA NVentures.\n",
       "\n",
       "[Maven AGI](https://www.mavenagi.com/resources/post/series-b), a customer experience AI company, raised a $50M Series B from Dell Technologies Capital, Cisco Investments and SE Ventures.\n",
       "\n",
       "[Thinking Machines Lab](https://www.ft.com/content/9edc67e6-96a9-4d2b-820d-57bc1279e358), Mira Murati’s AGI company, raised $2B at a $10B valuation led by Andreessen Horowitz.\n",
       "\n",
       "[Commure](https://www.commure.com/blog/commure-secures-200m-to-accelerate-ai-powered-healthcare-transformation), the AI-powered healthcare company, raised $200M in growth capital from General Catalyst’s CVF.\n",
       "\n",
       "[Decagon](https://decagon.ai/resources/series-c-announcement), the conversational AI company, raised a $131M Series C at a $1.5B valuation from Accel and Andreessen Horowitz.\n",
       "\n",
       "[Genesis Robotics](https://sifted.eu/articles/exclusive-genesis-robotics-85m-round), a full-stack robotics company built around the generative physics engine by the [same name](https://genesis-embodied-ai.github.io/), raised an $85M round co-led by Khosla Ventures and Eclipse Ventures.\n",
       "\n",
       "[Abridge](https://techcrunch.com/2025/06/24/in-just-4-months-ai-medical-scribe-abridge-doubles-valuation-to-5-3b), the medical notes automation startup, raised a $300M Series E at a $5.3B valuation from Andreessen Horowitz and Khosla Ventures.\n",
       "\n",
       "[OpenRouter](https://www.globenewswire.com/news-release/2025/06/25/3105125/0/en/OpenRouter-raises-40-million-to-scale-up-multi-model-inference-for-enterprise.html), the unified interface for LLM inference, raised $40M across seed and Series A led by Andreessen Horowitz and Menlo Ventures.\n",
       "\n",
       "[Metaview](https://fortune.com/2025/06/25/uber-palantir-alums-metaview-raise-35m-ai-revolution-recruitment-hiring/), the AI recruitment tech company, raised a $35M Series B led by Google Ventures with Plural and Vertex Ventures.\n",
       "\n",
       "[Wispr Flow](https://techcrunch.com/2025/06/24/wispr-flow-raises-30m-from-menlo-ventures-for-its-ai-powered-dictation-app/), the AI-powered dictation app, raised a $30M Series A from Menlo Ventures and NEA.\n",
       "\n",
       "[Lyceum](https://tech.eu/2025/06/24/sovereign-by-design-lyceum-emerges-with-eur103m-to-redefine-cloud-infrastructure-in-europe/), a “sovereign” cloud provider for AI, raised a €10.3M pre-seed led by Redalpine with 10x Founders.\n",
       "\n",
       "[Nominal](https://blog.nominal.io/series-b), modernizing hardware testing, raised a $75M Series B led by Sequoia Capital.\n",
       "\n",
       "[Glean](https://www.glean.com/press/glean-raises-150m-series-f-at-7-2b-valuation-to-accelerate-enterprise-ai-agent-innovation-globally?utm_source=chatgpt.com), the enterprise search company, raised a $150M Series F at a $7.2B valuation led by Wellington Management.\n",
       "\n",
       "[Pano AI](https://www.globenewswire.com/news-release/2025/06/16/3099902/0/en/Wildfire-Tech-Comes-of-Age-Pano-AI-Raises-44M-Series-B-Led-by-Giant-Ventures-to-Scale-Early-Detection-Infrastructure.html?utm_source=chatgpt.com), the wildfire-detection company, raised a $44M Series B from Giant Ventures, Liberty Mutual Strategic Ventures and Tokio Marine Future Fund.\n",
       "\n",
       "[Traversal](https://fortune.com/2025/06/18/traversal-emerges-from-stealth-with-48-million-from-sequoia-and-kleiner-perkins-to-reimagine-site-reliability-in-the-ai-era/), a startup focused on observability and site reliability engineering, raised $48M in its seed and Series A financing rounds led by Sequoia and Kleiner Perkins.\n",
       "\n",
       "[Delphi](https://www.delphi.ai/blog/delphi-raises-16m-series-a-from-sequoia), the AI platform for creating interactive \"digital minds,\" raised a $16M Series A from Sequoia Capital, with participation from Menlo & Anthropic’s Anthology Fund and Proximity Ventures.\n",
       "\n",
       "### Rumored investments\n",
       "\n",
       "[Lovable](https://techcrunch.com/2025/07/02/lovable-on-track-to-raise-150m-at-2b-valuation/), the Swedish AI startup vibe coding frontend applications, is rumored to be raising $150M at a $2B valuation.\n",
       "\n",
       "[PhysicsX](https://www.ft.com/content/db2b25e0-da61-42d3-932a-991b12e5476a), the UK physics simulation startup working in the industrial and defense sectors, is nearing a $1B valuation in its latest round.\n",
       "\n",
       "### **Acquisitions**\n",
       "\n",
       "[Qualcomm](https://investor.qualcomm.com/news-events/press-releases/news-details/2025/Qualcomm-to-Acquire-Alphawave-Semi/default.aspx), the US chipmaker, acquired Alphawave, a UK-based public company building semiconductors, for $2.4B. The company makes high-speed connectivity and compute chiplets, enabling fast data transfer with lower power consumption for applications like data centers, AI, 5G, and autonomous vehicles. This connectivity IP is said to complement Qualcomm's existing CPU and NPU processors, particularly for AI workloads.\n",
       "\n",
       "[Clio](https://www.clio.com/about/press/clio-signs-definitive-agreement-to-acquire-vlex/), the legal-tech leader, acquired vLex for $1B in cash and stock. This deal sees Clio bolt vLex’s AI-powered legal-research engine onto its practice-management suite so lawyers can search the world’s case law, draft filings, bill clients and track matters inside a single “legal OS.” The deal fast-forwards Clio’s agentic-AI roadmap, lets it sell up-market to large firms and new civil-law jurisdictions, and gives the combined company a proprietary corpus of workflow and primary-law data that can feed its own domain-specific LLMs while trimming licensing costs.\n",
       "\n",
       "[Figma](https://fortune.com/2025/07/02/figma-ipo-s-1-filing-growth-profitability-dual-class-share-structure-dylan-field-nyse-fig/), the design collaboration software company, filed for an IPO expected to raise up to $1.5B at a $15-20B valuation. This is a huge deal for the tech industry following the company’s failed $20B acquisition by Adobe due to anti-trust. Figma has since accelerated to almost $800m in revenue with 13M monthly active users and 95% of the Fortune 500 companies on its platform. The company has pushed into generative AI, launching new products such as Make, and weaving an AI assistant into its core surface.\n",
       "\n",
       "[Predibase](https://predibase.com/blog/predibase-will-be-joining-forces-with-rubrik), the AI company spun out of Chris Re’s group at Stanford to productise Ludvig, was acquired by Rubrik (a publicly listed cybersecurity company) to accelerate agentic-AI adoption. The price was undisclosed and rumored to be above $100M.\n",
       "\n",
       "[Helsing](https://www.ft.com/content/cdc02d96-13b5-4ca2-aa0b-1fc7568e9fa0), a German company specializing in AI and software solutions for defense, acquired Grob Aircraft, the producer of the G120TP military trainer, from H3 Aerospace. While the deal price was not disclosed, the rationale looks to be about vertical integration. By bringing a 275-person composite-aircraft factory and its G 120-series trainer line in-house, Helsing gains a purpose-built airframe on which it can iterate and certify its Cirra electronic-warfare AI and other onboard autonomy much faster than if it had to rely on third-party OEMs. The move deepens an existing test-bed partnership, anchors production in Europe and gives Helsing its own hardware-plus-software stack. This is an essential step toward fielding scalable, AI-native surveillance drones and light combat aircraft while reinforcing Europe’s drive for defence-technology sovereignty.\n",
       "\n",
       "[CoreWeave](https://coreweave.com/news/coreweave-to-acquire-core-scientific), the AI hyperscaler, acquired Core Scientific, a leading data center infrastructure provider, in an all-stock transaction valued at approximately $9 billion.\n",
       "\n",
       "[Superhuman](https://x.com/Superhuman/status/1940078856586571811), the email productivity company, was acquired by Grammarly. The acquisition price was not disclosed.\n",
       "\n",
       "[Seek AI](https://techcrunch.com/2025/06/02/ibm-acquires-data-analysis-startup-seek-ai-opens-ai-accelerator-in-nyc/), enabling natural language queries on enterprise data, was acquired by IBM for an undisclosed price.\n",
       "\n",
       "[Brainlab](https://www.reuters.com/business/finance/brainlab-ipo-expected-price-80-euros-per-share-bookrunner-says-2025-06-30/), the German med-tech firm that specializes in robotic surgery equipment and medical imaging tools, plans an IPO at €80 per share valuing the company at €1.7-2.1B.\n",
       "\n",
       "[Snyk](https://snyk.io/news/snyk-acquires-invariant-labs-to-accelerate-agentic-ai-security-innovation/), the secure-AI software leader, acquired Invariant Labs for an undisclosed price. The startup was spun out of an ETHZ lab that previously spawned DeepCode, also previously acquired by Snyk. Invariant was focused on productivising research to make agents more secure (e.g. [LMQL](https://github.com/eth-sri/lmql)).\n",
       "\n",
       "The team behind [Crossing Minds](https://techcrunch.com/2025/06/27/openai-hires-team-behind-ai-recommendation-startup-crossing-minds/), an AI-recommendation startup, was acquired by OpenAI.\n",
       "\n",
       "#### Share this post\n",
       "\n",
       "![]()\n",
       "![Guide to AI]()\n",
       "\n",
       "#### Discussion about this post\n",
       "\n",
       "![User's avatar]()\n",
       "![Renaud Gaudron's avatar]()\n",
       "\n",
       "Great summary! Thanks for sharing (and for including a voiceover!)\n",
       "\n",
       "No posts\n",
       "\n",
       "Ready for more?\n",
       "\n",
       "#### Share\n",
       "URL: https://nathanbenaich.substack.com/p/your-guide-to-ai-july-2025\n",
       "\n",
       "2. **Latest AI Breakthroughs and News: May, June, July 2025**\n",
       "Summary: Wondering what's happening in the AI world? Here are the latest AI breakthroughs and news that are shaping the world around us!\n",
       "URL: https://www.crescendo.ai/news/latest-ai-news-and-updates\n",
       "\n",
       "3. **27 of the best large language models in 2025 - TechTarget**\n",
       "Summary: ## Generative artificial intelligence, or GenAI, uses sophisticated algorithms to organize large, complex data sets into meaningful clusters of information to create new content, including text, images and audio, in response to a query or prompt. While the technology is still in relatively early -- and volatile -- days, progress thus far has already resulted in generative AI fundamentally changing enterprise technology and transforming how businesses operate. This guide takes a deeper look at how GenAI works and its implications, with hyperlinks throughout to guide you to articles, tips and definitions providing even more detailed explanations.\n",
       "\n",
       "# 27 of the best large language models in 2025\n",
       "\n",
       "## Large language models have been affecting search for years and have been brought to the forefront by ChatGPT and other chatbots.\n",
       "\n",
       "Large language models are the dynamite behind the [generative AI](https://www.techtarget.com/searchenterpriseai/definition/generative-AI) boom. However, they've been around for a while.\n",
       "\n",
       "[LLMs](https://www.techtarget.com/whatis/definition/large-language-model-LLM) are black box AI systems that use deep learning on extremely large datasets to understand and generate new text. Modern LLMs began taking shape in 2014 when the attention mechanism -- a machine learning technique designed to mimic human cognitive attention -- was introduced in a [research paper](https://arxiv.org/abs/1409.0473) titled \"Neural Machine Translation by Jointly Learning to Align and Translate.\" In 2017, that attention mechanism was honed with the introduction of the transformer model in another [paper](https://arxiv.org/abs/1706.03762), \"Attention Is All You Need.\"\n",
       "\n",
       "Some of the most well-known language models today are based on the transformer model, including the [generative pre-trained transformer series](https://www.techtarget.com/searchenterpriseai/feature/ChatGPT-vs-GPT-How-are-they-different) of LLMs and bidirectional encoder representations from transformers (BERT).\n",
       "\n",
       "[ChatGPT](https://www.techtarget.com/whatis/definition/ChatGPT), which runs on a set of language models from OpenAI, attracted more than 100 million users just two months after its release in 2022. Since then, many competing models have been released. Some belong to big companies such as Google, Amazon and Microsoft; others are open source.\n",
       "\n",
       "Constant developments in the field can be difficult to keep track of. Here are some of the most influential models, both past and present. Included in it are models that paved the way for today's leaders as well as those that could have a significant effect in the future.\n",
       "\n",
       "This article is part of\n",
       "\n",
       "### [What is GenAI? Generative AI explained](https://www.techtarget.com/searchenterpriseai/definition/generative-AI)\n",
       "\n",
       "## Top current LLMs\n",
       "\n",
       "Below are some of the most relevant large language models today. They do natural language processing and influence the architecture of future models.\n",
       "\n",
       "### BERT\n",
       "\n",
       "[BERT](https://www.techtarget.com/searchenterpriseai/definition/BERT-language-model) is a family of LLMs that Google introduced in 2018. BERT is a [transformer-based](https://www.techtarget.com/searchenterpriseai/tip/GAN-vs-transformer-models-Comparing-architectures-and-uses) model that can convert sequences of data to other sequences of data. BERT's architecture is a stack of transformer encoders and features 342 million parameters. BERT was pre-trained on a large corpus of data then fine-tuned to perform specific tasks along with natural language inference and sentence text similarity. It was used to improve query understanding in the 2019 iteration of Google search.\n",
       "\n",
       "### Claude\n",
       "\n",
       "The [Claude LLM](https://www.techtarget.com/searchenterpriseai/feature/Claude-AI-vs-ChatGPT-How-do-they-compare) focuses on constitutional AI, which shapes AI outputs guided by a set of principles that aim to make the AI assistant it powers helpful, harmless and accurate. Claude was created by the company Anthropic. Claude's latest iterations understand nuance, humor and complex instructions better than earlier versions of the LLM. They also have broad programming capabilities that make them well-suited for application development.\n",
       "\n",
       "There are three primary branches of Claude -- Opus, Haiku and Sonnet. The Claude Sonnet 4 and Claude Opus 4 models debuted in early 2025. Opus 4, the premium model, can perform long-running tasks and [agentic](https://www.techtarget.com/searchenterpriseai/definition/agentic-AI) workflows. Sonnet 4, the efficiency-focused model, shows continued improvement in coding, reasoning and instruction-following compared to previous iterations. Both models also include:\n",
       "\n",
       "In October 2024, Claude added an experimental [computer-use AI tool](https://www.techtarget.com/searchenterpriseai/news/366613946/Anthropic-adds-computer-use-AI-tool-to-Claude) in public beta that enables the LLM to use a computer like a human does. It's available to developers via the API.\n",
       "\n",
       "### Cohere\n",
       "\n",
       "Cohere is an enterprise AI platform that provides several LLMs including Command, Rerank and Embed. These [LLMs can be custom-trained](https://www.techtarget.com/searchenterpriseai/tip/How-to-train-an-LLM-on-your-own-data) and fine-tuned to a specific company's use case. The company that created the Cohere LLM was founded by one of the authors of Attention Is All You Need.\n",
       "\n",
       "### DeepSeek-R1\n",
       "\n",
       "[DeepSeek](https://www.techtarget.com/whatis/feature/DeepSeek-explained-Everything-you-need-to-know)-R1 is an open-source reasoning model for tasks with complex reasoning, mathematical problem-solving and logical inference. The model uses reinforcement learning techniques to refine its reasoning ability and solve complex problems. DeepSeek-R1 can perform critical problem-solving through self-verification, [chain-of-thought](https://www.techtarget.com/searchenterpriseai/definition/chain-of-thought-prompting) reasoning and reflection.\n",
       "\n",
       "### Ernie\n",
       "\n",
       "Ernie is Baidu's large language model powering the Ernie chatbot. The bot was released in August 2023 and has garnered more than 45 million users. Near the time of its release, it was rumored to have 10 trillion parameters, which turned out to be an overestimation -- later models have parameter counts in the billions. More recent versions of the Ernie chatbot include Ernie 4.5 and Ernie X1. The recent models are based on a [mixture-of-experts](https://www.techtarget.com/searchenterpriseai/feature/Mixture-of-experts-models-explained-What-you-need-to-know) architecture. Baidu open sourced it's Ernie 4.5 LLM series in 2025.\n",
       "\n",
       "### Falcon\n",
       "\n",
       "Falcon is a family of transformer-based modelsdeveloped by the Technology Innovation Institute. It is open source and has multi-lingual capabilities. Falcon 2 is available in an 11 billion parameter version that provides [multimodal](https://www.techtarget.com/searchenterpriseai/definition/multimodal-AI) capabilities for both text and vision. Falcon 3 is available in several sizes ranging from 1-10 billion parameters.\n",
       "\n",
       "The Falcon series also includes a pair of larger models with Falcon 40B and Falcon 180B, as well as several specialized models. Falcon models are available on GitHub as well as on cloud providers including Amazon.\n",
       "\n",
       "### Gemini\n",
       "\n",
       "[Gemini](https://www.techtarget.com/searchenterpriseai/definition/Google-Bard) is Google's family of LLMs that power the company's chatbot of the same name. The model replaced Palm in powering the chatbot, which was rebranded from Bard to Gemini upon the model switch. Gemini models are multimodal, meaning they can handle images, audio and video as well as text. Gemini is also integrated in many Google applications and products. It comes in several sizes -- Ultra, Pro, Flash and Nano. Ultra is the largest and most capable model, Pro is the mid-tier model, Flash prioritizes speed for agentic systems and real-time applications, and Nano is the smallest model, designed for efficiency with on-device tasks.\n",
       "\n",
       "Among the most recent models at the time of this writing is [Gemini 2.5 Pro](https://www.techtarget.com/whatis/feature/Google-Gemini-25-Pro-explained-Everything-you-need-to-know) and Gemini 2.5 Flash.\n",
       "\n",
       "### Gemma\n",
       "\n",
       "[Gemma](https://www.techtarget.com/searchenterpriseai/definition/Gemma) is a family of open-source language models from Google that were trained on the same resources as Gemini. Gemma 2 was released in June 2024 in two sizes -- a 9 billion parameter model and a 27 billion parameter model. Gemma 3 was released in March 2025, with 1B, 4B, 12B and 27B versions, and has expanded capabilities. Gemma models can [run locally](https://www.techtarget.com/searchenterpriseai/tip/How-to-run-LLMs-locally-Hardware-tools-and-best-practices) on a personal computer, and are also available in Google Vertex AI.\n",
       "\n",
       "### GPT-3\n",
       "\n",
       "[GPT-3](https://www.techtarget.com/searchenterpriseai/definition/GPT-3) is OpenAI's large language model with more than 175 billion parameters, released in 2020. GPT-3 uses a decoder-only transformer architecture. GPT-3 is 10 times larger than its predecessor. GPT-3's training data includes Common Crawl, WebText2, Books1, Books2 and Wikipedia.\n",
       "\n",
       "GPT-3 is the last of the GPT series of models in which OpenAI made the precise parameter counts publicly available. The GPT series was first introduced in 2018 with OpenAI's paper \"Improving Language Understanding by Generative Pre-Training.\"\n",
       "\n",
       "### GPT-3.5\n",
       "\n",
       "GPT-3.5 is an upgraded version of GPT-3. It was fine-tuned using [reinforcement learning from human feedback](https://www.techtarget.com/whatis/definition/reinforcement-learning-from-human-feedback-RLHF). There are several models, with GPT-3.5 Turbo being the most capable, according to OpenAI. GPT-3.5's training data extends to September 2021.\n",
       "\n",
       "It was also integrated into the Bing search engine but was replaced with GPT-4.\n",
       "\n",
       "### GPT-4\n",
       "\n",
       "[GPT-4](https://www.techtarget.com/whatis/definition/GPT-4) was released in 2023. Like the others in the OpenAI GPT family, it's a [transformer-based model](https://www.techtarget.com/searchenterpriseai/definition/transformer-model). Unlike the others, its parameter count has not been released to the public, though there are rumors that the model has more than 1 trillion. OpenAI describes GPT-4 as a multimodal model, meaning it can [process and generate both language and images](https://www.techtarget.com/searchenterpriseai/definition/vision-language-models-VLMs) as opposed to being limited to only language.\n",
       "\n",
       "GPT-4 demonstrated human-level performance in multiple academic exams. At the model's release, some speculated that GPT-4 came close to [artificial general intelligence](https://www.techtarget.com/searchenterpriseai/definition/artificial-general-intelligence-AGI), which means it is as smart or smarter than a human. That speculation turned out to be unfounded.\n",
       "\n",
       "### GPT-4o\n",
       "\n",
       "GPT-4 Omni ([GPT-4o](https://www.techtarget.com/whatis/feature/GPT-4o-explained-Everything-you-need-to-know)) is OpenAI's successor to GPT-4 and offers several improvements over the previous model. GPT-4o creates a more natural human interaction for ChatGPT and is a large multimodal model, accepting various inputs including audio, image and text. The conversations let users engage as they would in a normal human conversation, and the real-time interactivity can also pick up on emotions. GPT-4o can see photos or screens and ask questions about them during interaction.\n",
       "\n",
       "GPT-4o can respond in 232 milliseconds, similar to human response time and faster than GPT-4 Turbo. The free tier of ChatGPT runs on GPT-4o at the time of this writing.\n",
       "\n",
       "### Granite\n",
       "\n",
       "The IBM Granite family of models are fully open source under the Apache v.2 license. The first iteration of the open source model models [debuted in May 2024](https://www.techtarget.com/searchenterpriseai/news/366585895/IBM-moves-ahead-with-open-source-multi-model-AI-strategy), followed by [Granite 3.0](https://www.techtarget.com/searchenterpriseai/news/366614233/IBM-launches-new-generation-Granite-language-model) in October, Granite 3.1 in December 2024, Granite 3.2 in February 2025 and Granite 3.3 in April 2025.\n",
       "\n",
       "There are multiple variants in the Granite model family including General-purpose models (8B and 2B variants), guardrail model and Mixture-of-Experts models. While the model can be used for general purpose deployments, IBM itself is focusing deployment and optimization for enterprise use cases like customer service, IT automation and cybersecurity.\n",
       "\n",
       "### Grok\n",
       "\n",
       "Grok is an LLM from xAI that powers a chatbot of the same name. [Grok 3](https://www.techtarget.com/whatis/feature/Grok-3-model-explained-Everything-you-need-to-know) was released in May 2025. Grok 3 mini is a smaller, more cost-efficient version of Grok 3. The Grok 3 chatbot gives the user two modes that augment the chatbot's default state -- Think mode and DeepSearch mode. In Think mode, Grok uses chain-of-thought reasoning, explaining outputs in step-by-step detail. DeepSearch delves more deeply into internet research to produce an output. Grok performs particularly well -- relative to other top models -- on reasoning and mathematics [benchmarks](https://www.techtarget.com/searchsoftwarequality/tip/Benchmarking-LLMs-A-guide-to-AI-model-evaluation) such as GPQA and AIME. Grok 3 is closed source and written in primarily Rust and Python.  \n",
       "\n",
       "Grok's training infrastructure is composrd of the Colossus supercomputer, which contains more than 100,000 GPUs from Nvidia. The supercomputer was built in a repurposed Electrolux factory near Memphis, Tenn. xAI and Colossus have drawn criticism from residents and activists for a lack of transparency surrounding the [environmental effects](https://www.theguardian.com/technology/2025/apr/24/elon-musk-xai-memphis) of the facility's emissions.   \n",
       "\n",
       "The name Grok comes from Robert Heinlein's 1961 novel, *Stranger in a Strange Land*. The book coined the term to describe the ability to understand something deeply.\n",
       "\n",
       "### Lamda\n",
       "\n",
       "Lamda (Language Model for Dialogue Applications) is a family of LLMs developed by Google Brain in 2021. Lamda used a decoder-only transformer language model and was pre-trained on a large corpus of text. In 2022, Lambda gained widespread attention when then-Google engineer Blake Lemoine went public with claims that the [program was sentient](https://www.techtarget.com/searchenterpriseai/feature/Ex-Google-engineer-Blake-Lemoine-discusses-sentient-AI).\n",
       "\n",
       "### Llama\n",
       "\n",
       "Large Language Model Meta AI (Llama) is Meta's LLM which was first released in 2023. The Llama 3.1 models were released in July 2024, including both a 405 billion and 70 billion parameter model.\n",
       "\n",
       "The most recent version is [Llama 4](https://www.techtarget.com/whatis/feature/Meta-Llama-4-explained-Everything-you-need-to-know), which was released in April 2025. There are three main models -- Llama 4 Scout, Llama 4 Maverick and Llama 4 Behemoth. Behemoth is only available for preview at the time of this writing. Llama 4 is the first iteration of the Llama family to use a mixture-of-experts architecture.\n",
       "\n",
       "Previous iterations of Llama used a transformer architecture and were trained on a variety of public data sources, including webpages from CommonCrawl, GitHub, Wikipedia and Project Gutenberg. Earlier versions of Llama were effectively leaked and spawned many descendants, including Vicuna and Orca. Llama is available under an open license, allowing for [free use of the models](https://www.theserverside.com/video/Run-Llama-LLMs-on-your-laptop-with-Hugging-Face-and-Python). Lllama models are available in many locations including llama.com and Hugging Face.\n",
       "\n",
       "### Mistral\n",
       "\n",
       "[Mistral](https://www.techtarget.com/searchenterpriseai/news/366625822/What-differentiates-Mistral-AI-reasoning-model-Magistral) is a family of mixture-of-experts models from Mistral AI. Mistral Large 2 was first released in July 2024. The model operates with 123 billion parameters and a 128k context window, supporting dozens of languages including French, German, Spanish, Italian and many others, along with more than 80 coding languages. In November 2024, Mistral released Pixtral Large, a 124-billion-parameter multimodal model that can handle text and visual data. Mistral Medium 3 was released in May 2025, which is touted as their \"frontier-class multimodal model\".\n",
       "\n",
       "Mistral models are available via Mistral's API to those with a Mistral billing account.\n",
       "\n",
       "### o1\n",
       "\n",
       "The [OpenAI o1](https://www.techtarget.com/whatis/feature/OpenAI-o1-explained-Everything-you-need-to-know) model family was first introduced in Sept. 2024. The o1 model's focus is to provide what OpenAI refers to as - reasoning models, that can reason through a problem or query before offering a response.\n",
       "\n",
       "The o1 models excel in STEM fields, with strong results in mathematical reasoning (scoring 83% on the International Mathematics Olympiad compared to GPT-4o's 13%), code generation and scientific research tasks. While they offer enhanced reasoning and improved safety features, they operate more slowly than previous models due to their thorough reasoning processes and come with certain limitations, such as restricted access features and higher API costs. The models are available to ChatGPT Plus and Team users, with varying access levels for different user categories.\n",
       "\n",
       "### o3\n",
       "\n",
       "OpenAI introduced the successor model, o3, in December 2024. According to OpenAI, o3 is designed to handle tasks with more analytical thinking, problem-solving and complex reasoning and will improve o1's capabilities and performance. The [o3 model](https://www.techtarget.com/whatis/feature/OpenAI-o3-explained-Everything-you-need-to-know) became available to the public in June 2025.\n",
       "\n",
       "### o4-mini\n",
       "\n",
       "Like [others in the o-series](https://www.techtarget.com/searchenterpriseai/news/366622996/Whats-new-and-not-new-with-OpenAIs-latest-reasoning-models), o4-mini is a reasoning model that aims to excel at tasks that require complex reasoning and problem-solving. OpenAI claims that o-4 mini is superior to o3-mini across all key benchmarks. It comes in o-4-mini and o4-mini-high, which uses more extensive reasoning for complex problems. Just like other mini variants from OpenAI, it is designed to be especially cost-efficient. The model also uses a technique called deliberative alignment, which aims to identify attempts to exploit the system and create unsafe content.\n",
       "\n",
       "### Orca\n",
       "\n",
       "Orca is an LLM developed by Microsoft that has 13 billion parameters. It aims to improve on advancements made by other models by imitating the reasoning procedures achieved by LLMs. The research surrounding Orca involved teaching smaller models to reason the same way larger models do. Orca 2 was built on top of the 7 billion and 13 billion parameter versions of Llama 2.\n",
       "\n",
       "### Palm\n",
       "\n",
       "The [Pathways Language Model](https://www.techtarget.com/whatis/definition/Pathways-Language-Model-PaLM) is a 540 billion parameter transformer-based model from Google powering its AI chatbot [Bard](https://www.techtarget.com/searchenterpriseai/definition/Google-Bard). It was trained across multiple [TPU](https://cloud.google.com/tpu/docs/intro-to-tpu) 4 Pods -- Google's custom hardware for machine learning. Palm specializes in reasoning tasks such as coding, math, classification and question answering. Palm also excels at decomposing complex tasks into simpler subtasks.\n",
       "\n",
       "Palm gets its name from a Google research initiative to build Pathways, aiming to create a single model that serves as a foundation for multiple use cases. In October 2024, the Palm API was deprecated, and users were encouraged to migrate to Gemini.\n",
       "\n",
       "### Phi\n",
       "\n",
       "Phi is a transformer-based language model from Microsoft. The Phi 3.5 models were first released in August 2024. Phi-4 models were released late 2024 and early 2025. The series includes the base model, Phi-4-reasoning, Phi-4-reasoning-plus, Phi-4-mini-reasoning and Phi-4-mini-instruct.\n",
       "\n",
       "Released under a Microsoft-branded MIT License, they are available for developers to download, use, and modify without restrictions, including for commercial purposes.\n",
       "\n",
       "### Qwen\n",
       "\n",
       "Qwen is large family of open models developed by Chinese internet giant Alibaba Cloud. The newest set of models are the Qwen 3 suite, which was pre-trained on almost twice the number of tokens that its predecessor was trained on. These models are suitable for a wide range of tasks, including code generation, structured data understanding, mathematical problem-solving as well as general language understanding and generation.\n",
       "\n",
       "### StableLM\n",
       "\n",
       "StableLM is a series of open language models developed by Stability AI, the company behind image generator Stable Diffusion.\n",
       "\n",
       "StableLM 2 debuted in January 2024 initially with a 1.6 billion parameter model. In April 2024 that was expanded to also include a 12 billion parameter model. StableLM 2 supports seven languages: English, Spanish, German, Italian, French, Portuguese, and Dutch. Stability AI positions these models as offering different options for various use cases, with the 1.6B model suitable for specific, narrow tasks and faster processing while the 12B model provides more capability but requires more computational resources.\n",
       "\n",
       "### Tülu 3\n",
       "\n",
       "Allen Institute for AI's Tülu 3 is an open-source 405 billion-parameter LLM. The Tülu 3 405B model has post-training methods that combine supervised fine-tuning and reinforcement learning at a larger scale. Tülu 3 uses a \"reinforcement learning from verifiable rewards\" framework for fine-tuning tasks with verifiable outcomes -- such as solving mathematical problems and following instructions.\n",
       "\n",
       "### Vicuna 33B\n",
       "\n",
       "Vicuna is another influential open source LLM derived from Llama. It was developed by LMSYS and was fine-tuned using data from sharegpt.com. It is smaller and less capable that GPT-4 according to several benchmarks but does well for a model of its size. Vicuna has only 33 billion parameters.\n",
       "\n",
       "## LLM precursors\n",
       "\n",
       "Although LLMs are a recent phenomenon, their precursors go back decades. Learn how recent precursor Seq2Seq and distant precursor ELIZA set the stage for modern LLMs.\n",
       "\n",
       "### Seq2Seq\n",
       "\n",
       "Seq2Seq is a deep learning approach used for machine translation, image captioning and natural language processing. It was developed by Google and underlies some more modern LLMs, including LaMDA. Seq2Seq also underlies AlexaTM 20B, Amazon's large language model. It uses a mix of encoders and decoders.\n",
       "\n",
       "### Eliza\n",
       "\n",
       "Eliza was an [early natural language processing program](https://www.techtarget.com/searchenterpriseai/tip/History-of-generative-AI-innovations-spans-9-decades) created in 1966. It is one of the earliest examples of a language model. Eliza simulated conversation using pattern matching and substitution. Eliza, running a certain script, could parody the interaction between a patient and therapist by applying weights to certain keywords and responding to the user accordingly. The creator of Eliza, Joshua Weizenbaum, wrote a book on the limits of computation and artificial intelligence.\n",
       "\n",
       "*Sean Michael Kerner is an IT consultant, technology enthusiast and tinkerer. He has pulled Token Ring, configured NetWare and been known to compile his own Linux kernel. He consults with industry and media organizations on technology issues.*\n",
       "\n",
       "*Ben Lutkevich is site editor for Informa TechTarget Software Quality. Previously, he wrote definitions and features for Whatis.com.*\n",
       "\n",
       "#### Next Steps\n",
       "\n",
       "[Generative AI challenges that businesses should consider](https://www.techtarget.com/searchenterpriseai/tip/Generative-AI-challenges-that-businesses-should-consider)\n",
       "\n",
       "[Generative AI ethics: Biggest concerns](https://www.techtarget.com/searchenterpriseai/tip/Generative-AI-ethics-8-biggest-concerns)\n",
       "\n",
       "[Generative AI landscape: Potential future trends](https://www.techtarget.com/searchenterpriseai/tip/Generative-AI-landscape-Potential-future-trends)\n",
       "\n",
       "[Generative models: VAEs, GANs, diffusion, transformers, NeRFs](https://www.techtarget.com/searchenterpriseai/tip/Generative-models-VAEs-GANs-diffusion-transformers-NeRFs)\n",
       "\n",
       "[AI content generators to explore](https://www.techtarget.com/whatis/feature/AI-content-generators-to-explore)\n",
       "\n",
       "#### Related Resources\n",
       "\n",
       "#### Dig Deeper on Data analytics and AI\n",
       "\n",
       "![]()\n",
       "\n",
       "##### Oracle adds xAI Grok models to OCI\n",
       "\n",
       "![EstherShittu]()\n",
       "![]()\n",
       "\n",
       "##### Benchmarking LLMs: A guide to AI model evaluation\n",
       "\n",
       "![MattHeusser](https://www.techtarget.com/rms/online## Meta Llama 4 explained: Everything you need to know\n",
       "\n",
       "![SeanKerner](https://www.techtarget.com/rms/online# With Llama 4, Meta ups stakes in open model race\n",
       "\n",
       "![ShaunSutner](https://www.techtarget.com/rms/onlines is a term that combines the words 'telecommunications' and 'informatics' to describe the use of communications and IT ...\n",
       "\n",
       "The domain name system (DNS) is a naming database in which internet domain names are located and translated into Internet ...\n",
       "\n",
       "Attenuation is a general term referring to when any type of signal -- digital or analog -- reduces in strength.\n",
       "\n",
       "CISO as a service, or CISOaaS, is the outsourcing of CISO (chief information security officer) and information security ...\n",
       "\n",
       "Post-quantum cryptography, also known as quantum encryption or PQC, is the development of cryptographic systems for classical ...\n",
       "\n",
       "A message authentication code (MAC) is a cryptographic checksum applied to a message to guarantee its integrity and authenticity.\n",
       "\n",
       "A procurement plan -- also called a procurement management plan -- is a document that is used to manage the process of finding ...\n",
       "\n",
       "Quantum circuits are systems consisting of logic gates that operate on quantum bits (qubits) to process information and perform ...\n",
       "\n",
       "Prescriptive analytics is a type of data analytics that provides guidance on what should happen next.\n",
       "\n",
       "A talent pipeline is a pool of candidates who are ready to fill a position.\n",
       "\n",
       "An applicant tracking system (ATS) is software that manages the recruiting and hiring process, including job postings and job ...\n",
       "\n",
       "Manager self-service is a type of human resource management (HRM) platform that gives supervisors immediate access to employee ...\n",
       "\n",
       "Field service management (FSM) is a system of managing off-site workers and the resources they require to do their jobs ...\n",
       "\n",
       "Customer service is the support organizations offer to customers before, during and after purchasing a product or service.\n",
       "\n",
       "Quality of experience (QoE or QoX) is a measure of the overall level of a customer's satisfaction and experience with a product ...\n",
       "\n",
       "All Rights Reserved. \n",
       "[Copyright 1999 - 2025](https://www.informatechtarget.com/terms-of-use), TechTarget  \n",
       "\n",
       "[Privacy Policy](https://www.informatechtarget.com/privacy-policy/)\n",
       "\n",
       "[Cookie Preferences](#) \n",
       "\n",
       "[Cookie Preferences](#) \n",
       "\n",
       "[Do Not Sell or Share My Personal Information](https://techtarget.zendesk.com/hc/en-us/requests/new?ticket_form_id=360004852434)\n",
       "URL: https://www.techtarget.com/whatis/feature/12-of-the-best-large-language-models\n",
       "\n",
       "4. **Language models recent news | AI Business**\n",
       "Summary: Explore the latest news and expert commentary on Language models, brought to you by the editors of AI Business.\n",
       "URL: https://aibusiness.com/nlp/language-models\n",
       "\n",
       "5. **AI News | Latest AI News, Analysis & Events**\n",
       "Summary: AI News reports on the latest artificial intelligence news and insights. Explore industry trends from the frontline of AI.\n",
       "URL: https://www.artificialintelligence-news.com/\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_items = \"\"\n",
    "for i, result in enumerate(tavily_results[\"results\"], start=1):\n",
    "    title = result.get(\"title\", \"No title\")\n",
    "    snippet = clean_raw_article(result.get(\"raw_content\") or result.get(\"content\") or \"\")\n",
    "    url = result.get(\"url\", \"\")\n",
    "    news_items += f\"{i}. **{title}**\\nSummary: {snippet}\\nURL: {url}\\n\\n\"\n",
    "\n",
    "display(Markdown(news_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea0480",
   "metadata": {},
   "source": [
    "### Summarize using Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b601a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = Anthropic(api_key = ANTHROPIC_API_KEY)\n",
    "reasoning_prompt = f\"\"\"\n",
    "Below are some recent news headlines related to AI:\n",
    "\n",
    "{news_items}\n",
    "\n",
    "You are an expert in AI communications and public perception. For each headline:\n",
    "- Summarize the core topic in 100 words\n",
    "- Explain in 1 line if this is effective for a LinkedIn audience (why or why not)\n",
    "- Rate each out of 10 for LinkedIn impact\n",
    "\n",
    "Then suggest the best 2 to share as a LinkedIn post.\n",
    "\"\"\"\n",
    "response = claude.messages.create(\n",
    "  model = \"claude-3-7-sonnet-20250219\",\n",
    "  system = \"You are an expert AI news summarizer and social media strategist.\",\n",
    "  messages = [\n",
    "    { \n",
    "      \"role\": \"user\", \n",
    "      \"content\": reasoning_prompt\n",
    "    }\n",
    "  ],\n",
    "  max_tokens = 1000\n",
    ")\n",
    "\n",
    "news_content = response.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "721c3d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Analysis of AI News Headlines for LinkedIn Sharing\n",
       "\n",
       "## 1. Nathan Benaich's \"Your guide to AI: July 2025\"\n",
       "\n",
       "**Core Topic Summary:**\n",
       "This comprehensive newsletter covers the latest developments in AI across multiple domains. Key highlights include Meta's restructuring with the formation of Meta Superintelligence Labs and significant talent acquisitions, revenue growth for companies like OpenAI ($10B) and Anthropic ($4B), regulatory developments including a landmark copyright ruling affecting AI training data, autonomous vehicle advancements from Wayve and Tesla, safety research from Anthropic testing AI agents under pressure, China's increasing investment in national AI projects, and numerous research breakthroughs in areas like binding affinity prediction, genomics, and video understanding.\n",
       "\n",
       "**LinkedIn Effectiveness:**\n",
       "Highly effective for LinkedIn as it provides comprehensive industry insights with specific figures and developments that professionals can reference in business conversations.\n",
       "\n",
       "**LinkedIn Impact Rating: 9/10**\n",
       "The newsletter's breadth, depth, and inclusion of business metrics makes it extremely valuable for professionals tracking AI developments.\n",
       "\n",
       "## 2. \"Latest AI Breakthroughs and News: May, June, July 2025\"\n",
       "\n",
       "**Core Topic Summary:**\n",
       "This headline appears to be a teaser for content covering recent AI breakthroughs spanning May through July 2025. However, without a descriptive summary, it's unclear what specific developments are covered. The headline suggests a compilation of recent advancements but lacks the specificity needed to evaluate its content depth.\n",
       "\n",
       "**LinkedIn Effectiveness:**\n",
       "Likely ineffective due to vague wording that doesn't communicate specific value or insights to professionals.\n",
       "\n",
       "**LinkedIn Impact Rating: 3/10**\n",
       "The headline lacks specificity and compelling hooks that would drive engagement on a professional platform.\n",
       "\n",
       "## 3. \"27 of the best large language models in 2025\"\n",
       "\n",
       "**Core Topic Summary:**\n",
       "This comprehensive guide catalogs 27 leading large language models as of 2025, offering detailed information about each model's capabilities, architecture, and applications. The article covers established models like BERT, Claude, GPT-4o, Gemini, and Llama 4, as well as newer entries like DeepSeek-R1, Granite, and Grok 3. For each model, it provides technical specifications, release history, use cases, and distinguishing features. The article also includes historical context by covering early precursors like ELIZA and Seq2Seq that laid the groundwork for modern LLMs.\n",
       "\n",
       "**LinkedIn Effectiveness:**\n",
       "Excellent for LinkedIn as it provides practical, comparative information that helps professionals make informed decisions about AI implementation.\n",
       "\n",
       "**LinkedIn Impact Rating: 8/10**\n",
       "The comprehensive nature and practical focus make this highly relevant for business professionals evaluating AI solutions.\n",
       "\n",
       "## 4. \"Language models recent news | AI Business\"\n",
       "\n",
       "**Core Topic Summary:**\n",
       "This appears to be a generic header for a section or category page on AI Business focused on language model news. Without additional context or specific content, it's difficult to evaluate the actual substance being offered.\n",
       "\n",
       "**LinkedIn Effectiveness:**\n",
       "Ineffective as it's simply a category label rather than actual content with insights.\n",
       "\n",
       "**LinkedIn Impact Rating: 1/10**\n",
       "This is a navigation label, not substantive content that would provide value on LinkedIn.\n",
       "\n",
       "## 5. \"AI News | Latest AI News, Analysis & Events\"\n",
       "\n",
       "**Core Topic Summary:**\n",
       "Similar to #4, this appears to be a generic header for an AI news section rather than a specific article or insight piece. The headline suggests broad coverage of AI news, analysis, and events but doesn't offer specific content to evaluate.\n",
       "\n",
       "**LinkedIn Effectiveness:**\n",
       "Ineffective as it lacks specific content or insights that would provide value to LinkedIn users.\n",
       "\n",
       "**LinkedIn Impact Rating: 1/10**\n",
       "Generic category headers don't provide the specific insights or value that drive LinkedIn engagement.\n",
       "\n",
       "## Recommendation for LinkedIn Sharing\n",
       "\n",
       "Based on the analysis, the two best articles to share on LinkedIn would be:\n",
       "\n",
       "1. **Nathan Benaich's \"Your guide to AI: July 2025\"** - This comprehensive newsletter provides actionable insights across multiple domains with specific figures and developments that professionals can reference. Its blend of business metrics, research highlights, and industry moves makes it ideal for generating meaningful professional discussion.\n",
       "\n",
       "2. **\"27 of the best large language models in 2025\"** - This detailed guide offers practical, comparative information that helps professionals make informed decisions about AI implementation. The comprehensive nature and focus on specific models make it a valuable resource for anyone considering or currently using AI solutions in their business.\n",
       "\n",
       "These two pieces provide the"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(news_content.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa6ae93",
   "metadata": {},
   "source": [
    "### Enchance Structure and Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92452993",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "system_message = \"You are a helpful assistant.\"\n",
    "\n",
    "reasoning_prompt = f\"\"\"\n",
    "I've been given this social media post\n",
    "\n",
    "I want you to analyze the style of writing and key points mentioned in the post and provide \n",
    "me with a reasoning as to why this post is effective or not effective for a LinkedIn audience\n",
    "for those who may have little to no knowledhe about AI.\n",
    "\n",
    "After this, restructure the post according to the suggestions you have provided.\n",
    "\n",
    "Please provide your reasoning in a few sentences.\n",
    "\n",
    "Here is the post for context:\n",
    "\n",
    "{news_content.text}\n",
    "\"\"\"\n",
    "\n",
    "compile = client.chat.completions.create(\n",
    "  model = \"o3-mini\",\n",
    "  messages = [\n",
    "    { \"role\": \"system\", \"content\": system_message },\n",
    "    { \"role\": \"user\", \"content\": reasoning_prompt }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c196802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Below is my analysis and reasoning, followed by a restructured version of the post:\n",
       "\n",
       "──────────────────────────────\n",
       "Analysis and Reasoning:\n",
       "• The original post uses a detailed, structured format with headings and ratings, which is great for professionals. It offers in‐depth summaries, specific business metrics, and comparisons that provide valuable context.\n",
       "• However, for LinkedIn users who have little or no knowledge about AI, some parts are overly technical and assume familiarity with the domain (e.g., specific model names, detailed financial figures). At times, the content can seem dense and the general sections (like category headers) may not offer actionable insights.\n",
       "• To be more effective for the broader professional audience, the post could simplify language, focus on clear, high-level takeaways, and provide context for technical details.\n",
       "\n",
       "──────────────────────────────\n",
       "Restructured Post:\n",
       "\n",
       "Title: AI News Headlines: What’s Worth Sharing on LinkedIn?\n",
       "\n",
       "1. Nathan Benaich’s “Your Guide to AI: July 2025”\n",
       "• Highlights: Covers the latest AI trends, including Meta’s new Superintelligence Labs, impressive revenue growth at companies like OpenAI and Anthropic, key regulatory changes, and breakthroughs in autonomous vehicles, genomics, and more.\n",
       "• Why It Works: Its mix of quantitative business metrics and industry insights offers professionals concrete talking points and a snapshot of the evolving AI landscape.\n",
       "• Impact Rating: 9/10\n",
       "• Note: An ideal share for professionals interested in both the business and technological sides of AI.\n",
       "\n",
       "2. “Latest AI Breakthroughs and News: May, June, July 2025”\n",
       "• Highlights: Promises a collection of recent AI developments.\n",
       "• Why It Falls Short: The lack of specific details makes it hard for someone unfamiliar with AI to understand the value of the content.\n",
       "• Impact Rating: 3/10\n",
       "\n",
       "3. “27 of the Best Large Language Models in 2025”\n",
       "• Highlights: Provides a detailed guide of 27 language models, presenting their capabilities, key features, and practical applications.\n",
       "• Why It Works: This guide compares various models and helps professionals understand which AI tools might work best for their business needs.\n",
       "• Impact Rating: 8/10\n",
       "• Note: Though technical, the clear comparisons lend valuable insights for decision-makers.\n",
       "\n",
       "4. “Language Models Recent News | AI Business”\n",
       "• Highlights: Appears to be a broad category label.\n",
       "• Why It Falls Short: It lacks specific insights or actionable content that would spark meaningful discussions.\n",
       "• Impact Rating: 1/10\n",
       "\n",
       "5. “AI News | Latest AI News, Analysis & Events”\n",
       "• Highlights: A broad header for AI news and events.\n",
       "• Why It Falls Short: Like the previous item, it doesn’t provide concrete examples or details that resonate with professionals new to AI.\n",
       "• Impact Rating: 1/10\n",
       "\n",
       "Recommendations:\n",
       "For LinkedIn sharing, focus on:\n",
       "• Nathan Benaich’s “Your Guide to AI: July 2025” – it blends business metrics and innovation insights.\n",
       "• “27 of the Best Large Language Models in 2025” – it offers a clear, comparative look at tools that are shaping AI adoption.\n",
       "\n",
       "──────────────────────────────\n",
       "This restructured post uses clear bullet points and simplified language while still highlighting the key takeaways, making it more accessible to professionals who may not be deeply familiar with AI."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reasoning_response = compile.choices[0].message.content\n",
    "display(Markdown(reasoning_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Engineering-Essentials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
